{"db":[{"meta":{"exported_on":1508350443793,"version":"009"},"data":{"app_fields":[],"app_settings":[],"apps":[],"permissions":[{"id":4,"uuid":"d1ab70fc-e23d-4851-9e72-590bb66abe53","name":"Export database","object_type":"db","action_type":"exportContent","object_id":null,"created_at":"2014-08-11T17:06:41.000Z","created_by":1,"updated_at":"2014-08-11T17:06:41.000Z","updated_by":1},{"id":5,"uuid":"396844e8-e705-4809-9ac5-e29d4a9bf8ac","name":"Import database","object_type":"db","action_type":"importContent","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":6,"uuid":"f770fc3b-18c5-4e57-8136-639983298620","name":"Delete all content","object_type":"db","action_type":"deleteAllContent","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":7,"uuid":"3ced687e-87b9-4064-b647-fe962f0f9b10","name":"Send mail","object_type":"mail","action_type":"send","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":8,"uuid":"255fc743-18cf-4377-9575-a3511e27c1ec","name":"Browse notifications","object_type":"notification","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":9,"uuid":"1c7aeba4-2978-4aad-9695-d7bf9e72762d","name":"Add notifications","object_type":"notification","action_type":"add","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":10,"uuid":"2270500b-4ac9-4f6d-8dff-10ac9c0803a1","name":"Delete notifications","object_type":"notification","action_type":"destroy","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":11,"uuid":"4163705b-ba30-480f-80b4-5078ea839b81","name":"Browse posts","object_type":"post","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":12,"uuid":"ffdb44f5-7a99-4325-ad85-8e9475e2f99b","name":"Read posts","object_type":"post","action_type":"read","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":13,"uuid":"f0d0e50e-765d-43f6-af24-d644ceaeb188","name":"Edit posts","object_type":"post","action_type":"edit","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":14,"uuid":"75310de3-9b19-4eb0-af33-a7797b865ee5","name":"Add posts","object_type":"post","action_type":"add","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":15,"uuid":"33ff1c91-722e-46c6-b6bc-0d6122814901","name":"Delete posts","object_type":"post","action_type":"destroy","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":16,"uuid":"42b2f2ee-b92c-42df-8234-d8482585a2c0","name":"Browse settings","object_type":"setting","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":17,"uuid":"8f87e859-7de7-45fc-8336-53b62ebe8256","name":"Read settings","object_type":"setting","action_type":"read","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":18,"uuid":"9ebbf4f7-78fc-4a24-91a4-59b622096091","name":"Edit settings","object_type":"setting","action_type":"edit","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":19,"uuid":"6c260005-7324-41fc-a706-86ca5be0506c","name":"Generate slugs","object_type":"slug","action_type":"generate","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":20,"uuid":"15e79776-ecfc-4835-b0ce-f4283ab519b8","name":"Browse tags","object_type":"tag","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":21,"uuid":"c41f2c99-7db2-443e-9cca-3cb1a3ffc3e8","name":"Read tags","object_type":"tag","action_type":"read","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":22,"uuid":"b279f365-b630-4e56-9351-bb12e165d473","name":"Edit tags","object_type":"tag","action_type":"edit","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":23,"uuid":"add39ec4-7901-4fc7-9eda-6d8bbff0c106","name":"Add tags","object_type":"tag","action_type":"add","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":24,"uuid":"185c0f49-6a9e-4369-a1f6-bab64dde2d10","name":"Delete tags","object_type":"tag","action_type":"destroy","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":25,"uuid":"8f13b4c9-42ec-496e-a4d5-dc4db13277c3","name":"Browse themes","object_type":"theme","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":26,"uuid":"5304e901-2884-4e78-ba79-a1a9c0ce90a9","name":"Edit themes","object_type":"theme","action_type":"edit","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":27,"uuid":"ecb01e97-cdd3-4af7-985f-768612a34587","name":"Browse users","object_type":"user","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":28,"uuid":"9fd0017d-89c7-4b4b-b185-ccb4bffb3c0c","name":"Read users","object_type":"user","action_type":"read","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":29,"uuid":"162a8c46-ad95-4c16-a878-d20bce4d31c3","name":"Edit users","object_type":"user","action_type":"edit","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":30,"uuid":"4ea23259-dcf0-4df6-b765-a90b6fde3afd","name":"Add users","object_type":"user","action_type":"add","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":31,"uuid":"a39c2ef2-8fdd-410a-b985-82285e7ad5c3","name":"Delete users","object_type":"user","action_type":"destroy","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":32,"uuid":"67316a3e-ab40-41f6-852c-bc151c2e45e8","name":"Assign a role","object_type":"role","action_type":"assign","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":33,"uuid":"20ed1477-d397-4c23-b7b9-564c1d31e100","name":"Browse roles","object_type":"role","action_type":"browse","object_id":null,"created_at":"2014-08-11T17:06:42.000Z","created_by":1,"updated_at":"2014-08-11T17:06:42.000Z","updated_by":1},{"id":34,"uuid":"2d885571-1c52-479b-9cc9-53b55af1837b","name":"Browse clients","object_type":"client","action_type":"browse","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":35,"uuid":"7b226874-a802-4d90-aa34-6d844a083a1d","name":"Read clients","object_type":"client","action_type":"read","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":36,"uuid":"2379ee16-32a4-49c6-a5e4-b88d6aab8180","name":"Edit clients","object_type":"client","action_type":"edit","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":37,"uuid":"34651e50-ca03-4afd-add5-51f016b265c2","name":"Add clients","object_type":"client","action_type":"add","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":38,"uuid":"a7feaf62-f766-418f-a889-174b1db00c2c","name":"Delete clients","object_type":"client","action_type":"destroy","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":39,"uuid":"87781108-a5e3-489a-827e-d5ef95f90a36","name":"Browse subscribers","object_type":"subscriber","action_type":"browse","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":40,"uuid":"a119f43a-c4cf-4a2e-80a2-82d33fccb55b","name":"Read subscribers","object_type":"subscriber","action_type":"read","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":41,"uuid":"e2fe5081-e264-4f9f-a4a7-99845ad9eea8","name":"Edit subscribers","object_type":"subscriber","action_type":"edit","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":42,"uuid":"426a7cd5-cee8-47e2-89df-e7b80309989e","name":"Add subscribers","object_type":"subscriber","action_type":"add","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":43,"uuid":"87478e79-20d1-4f45-bbd4-90ac76313a5c","name":"Delete subscribers","object_type":"subscriber","action_type":"destroy","object_id":null,"created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-05-18T12:58:56.000Z","updated_by":1},{"id":44,"uuid":"e5128aee-3906-48b7-9fd2-dc30016a7910","name":"Upload themes","object_type":"theme","action_type":"add","object_id":null,"created_at":"2016-08-29T13:54:17.000Z","created_by":1,"updated_at":"2016-08-29T13:54:17.000Z","updated_by":1},{"id":45,"uuid":"03c85621-00dc-4679-ab90-1cd02525c252","name":"Download themes","object_type":"theme","action_type":"read","object_id":null,"created_at":"2016-08-29T13:54:18.000Z","created_by":1,"updated_at":"2016-08-29T13:54:18.000Z","updated_by":1},{"id":46,"uuid":"7649a396-fac7-486a-a4d2-4308fc193e55","name":"Delete themes","object_type":"theme","action_type":"destroy","object_id":null,"created_at":"2016-08-29T13:54:18.000Z","created_by":1,"updated_at":"2016-08-29T13:54:18.000Z","updated_by":1}],"permissions_apps":[],"permissions_roles":[{"id":4,"role_id":1,"permission_id":4},{"id":5,"role_id":1,"permission_id":5},{"id":6,"role_id":1,"permission_id":6},{"id":7,"role_id":1,"permission_id":7},{"id":8,"role_id":1,"permission_id":8},{"id":9,"role_id":1,"permission_id":9},{"id":10,"role_id":1,"permission_id":10},{"id":11,"role_id":1,"permission_id":11},{"id":12,"role_id":1,"permission_id":12},{"id":13,"role_id":1,"permission_id":13},{"id":14,"role_id":1,"permission_id":14},{"id":15,"role_id":1,"permission_id":15},{"id":16,"role_id":1,"permission_id":16},{"id":17,"role_id":1,"permission_id":17},{"id":18,"role_id":1,"permission_id":18},{"id":19,"role_id":1,"permission_id":19},{"id":20,"role_id":1,"permission_id":20},{"id":21,"role_id":1,"permission_id":21},{"id":22,"role_id":1,"permission_id":22},{"id":23,"role_id":1,"permission_id":23},{"id":24,"role_id":1,"permission_id":24},{"id":25,"role_id":1,"permission_id":25},{"id":26,"role_id":1,"permission_id":26},{"id":27,"role_id":1,"permission_id":27},{"id":28,"role_id":1,"permission_id":28},{"id":29,"role_id":1,"permission_id":29},{"id":30,"role_id":1,"permission_id":30},{"id":31,"role_id":1,"permission_id":31},{"id":32,"role_id":1,"permission_id":32},{"id":33,"role_id":1,"permission_id":33},{"id":34,"role_id":2,"permission_id":11},{"id":35,"role_id":2,"permission_id":12},{"id":36,"role_id":2,"permission_id":13},{"id":37,"role_id":2,"permission_id":14},{"id":38,"role_id":2,"permission_id":15},{"id":39,"role_id":2,"permission_id":16},{"id":40,"role_id":2,"permission_id":17},{"id":41,"role_id":2,"permission_id":19},{"id":42,"role_id":2,"permission_id":20},{"id":43,"role_id":2,"permission_id":21},{"id":44,"role_id":2,"permission_id":22},{"id":45,"role_id":2,"permission_id":23},{"id":46,"role_id":2,"permission_id":24},{"id":47,"role_id":2,"permission_id":27},{"id":48,"role_id":2,"permission_id":28},{"id":49,"role_id":2,"permission_id":29},{"id":50,"role_id":2,"permission_id":30},{"id":51,"role_id":2,"permission_id":31},{"id":52,"role_id":2,"permission_id":32},{"id":53,"role_id":2,"permission_id":33},{"id":54,"role_id":3,"permission_id":11},{"id":55,"role_id":3,"permission_id":12},{"id":56,"role_id":3,"permission_id":14},{"id":57,"role_id":3,"permission_id":16},{"id":58,"role_id":3,"permission_id":17},{"id":59,"role_id":3,"permission_id":19},{"id":60,"role_id":3,"permission_id":20},{"id":61,"role_id":3,"permission_id":21},{"id":62,"role_id":3,"permission_id":23},{"id":63,"role_id":3,"permission_id":27},{"id":64,"role_id":3,"permission_id":28},{"id":65,"role_id":3,"permission_id":33},{"id":66,"role_id":1,"permission_id":34},{"id":67,"role_id":1,"permission_id":35},{"id":68,"role_id":1,"permission_id":36},{"id":69,"role_id":1,"permission_id":37},{"id":70,"role_id":1,"permission_id":38},{"id":71,"role_id":2,"permission_id":34},{"id":72,"role_id":2,"permission_id":35},{"id":73,"role_id":2,"permission_id":36},{"id":74,"role_id":2,"permission_id":37},{"id":75,"role_id":2,"permission_id":38},{"id":76,"role_id":3,"permission_id":34},{"id":77,"role_id":3,"permission_id":35},{"id":78,"role_id":3,"permission_id":36},{"id":79,"role_id":3,"permission_id":37},{"id":80,"role_id":3,"permission_id":38},{"id":81,"role_id":1,"permission_id":39},{"id":82,"role_id":1,"permission_id":40},{"id":83,"role_id":1,"permission_id":41},{"id":84,"role_id":1,"permission_id":42},{"id":85,"role_id":1,"permission_id":43},{"id":86,"role_id":2,"permission_id":42},{"id":87,"role_id":3,"permission_id":42},{"id":88,"role_id":1,"permission_id":44},{"id":89,"role_id":1,"permission_id":45},{"id":90,"role_id":1,"permission_id":46}],"permissions_users":[],"posts":[{"id":2,"uuid":"4ffa83ae-41b6-49e9-b565-4d0eb5cfb57e","title":"Unique Collections With HashSet<T>","slug":"hashset","markdown":"I used to say that [Dictionary &lt;TKey, TValue&gt;](http://msdn.microsoft.com/en-us/library/xfhwa508(v=vs.110).aspx) was my favorite C# feature. Dictionary offers great speed and versatility, but there are a few drawbacks that don't make it fit every situation: \n\n*   Attempting to add a key-value pair of an existing key throws an ArgumentException, causing the need to check first with [ContainsKey()](http://msdn.microsoft.com/en-us/library/kw5aaea4(v=vs.110).aspx)\n*   Sometimes I only want a collection of unique things, not key-value pairs of things\n\nHashSet is so appealing to me because it has the speed and uniqueness of Dictionary, but with added flexibility with fewer lines of code. The [HashSet&lt;T&gt;.Add](http://msdn.microsoft.com/en-us/library/bb353005(v=vs.110).aspx) method returns returns a boolean: true if that object was added to the HashSet, false if it already exists. This feature is what gives the HashSet its true power. With it, you can use the HashSet as a lightweight and fast collection of existing objects and the conditional Add() as a check before possibly attempting to modify other collections that would take more time. I've created a quick example of the HashSet in action in an ASP.NET MVC 5 project and pushed it to GitHub. [https://github.com/bgnicoll/HashsetExample](https://github.com/bgnicoll/HashsetExample) I also deployed to Azure for fun. I get 10 free sites and it can pull the repo directly from GitHub, why not? [http://hashset.azurewebsites.net/](http://hashset.azurewebsites.net/)\n\nIn the example, I simply created a HashSet&lt;string&gt; and gave the user an input to attempt to add something to it. I output the result to the console. One thing to note is the [constructor](http://msdn.microsoft.com/en-us/library/bb359100(v=vs.110).aspx) contains [StringComparer.OrdinalIgnoreCase](http://msdn.microsoft.com/en-us/library/system.stringcomparer.ordinalignorecase.aspx), which makes the HashSet case-insensitive. Maybe you want this, maybe you don't. ","html":"<p>I used to say that <a href=\"http://msdn.microsoft.com/en-us/library/xfhwa508(v=vs.110).aspx\">Dictionary &lt;TKey, TValue&gt;</a> was my favorite C# feature. Dictionary offers great speed and versatility, but there are a few drawbacks that don't make it fit every situation: </p>\n\n<ul>\n<li>Attempting to add a key-value pair of an existing key throws an ArgumentException, causing the need to check first with <a href=\"http://msdn.microsoft.com/en-us/library/kw5aaea4(v=vs.110).aspx\">ContainsKey()</a></li>\n<li>Sometimes I only want a collection of unique things, not key-value pairs of things</li>\n</ul>\n\n<p>HashSet is so appealing to me because it has the speed and uniqueness of Dictionary, but with added flexibility with fewer lines of code. The <a href=\"http://msdn.microsoft.com/en-us/library/bb353005(v=vs.110).aspx\">HashSet&lt;T&gt;.Add</a> method returns returns a boolean: true if that object was added to the HashSet, false if it already exists. This feature is what gives the HashSet its true power. With it, you can use the HashSet as a lightweight and fast collection of existing objects and the conditional Add() as a check before possibly attempting to modify other collections that would take more time. I've created a quick example of the HashSet in action in an ASP.NET MVC 5 project and pushed it to GitHub. <a href=\"https://github.com/bgnicoll/HashsetExample\">https://github.com/bgnicoll/HashsetExample</a> I also deployed to Azure for fun. I get 10 free sites and it can pull the repo directly from GitHub, why not? <a href=\"http://hashset.azurewebsites.net/\">http://hashset.azurewebsites.net/</a></p>\n\n<p>In the example, I simply created a HashSet&lt;string&gt; and gave the user an input to attempt to add something to it. I output the result to the console. One thing to note is the <a href=\"http://msdn.microsoft.com/en-us/library/bb359100(v=vs.110).aspx\">constructor</a> contains <a href=\"http://msdn.microsoft.com/en-us/library/system.stringcomparer.ordinalignorecase.aspx\">StringComparer.OrdinalIgnoreCase</a>, which makes the HashSet case-insensitive. Maybe you want this, maybe you don't. </p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2014-05-15T17:34:00.000Z","created_by":1,"updated_at":"2014-08-18T17:37:08.000Z","updated_by":1,"published_at":"2014-05-15T17:34:00.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":6,"uuid":"9a32560a-e655-4c9f-9b79-f47312329204","title":"Convert Dictionary<int, bool> to Dictionary<int, enum> With Enumerable.ToDictionary()","slug":"convert_dictionary_int_bool_to_dictionary_int_enum_with_enumerable_to_dictionary_","markdown":"I'm getting some data in the form of a string as a key value pair collection of integer IDs and a boolean value(a status represented on the page by a checkbox). First, I call DeserializeObject() from the Json.NET library and convert the string to a Dictionary&lt;int, bool&gt;. I can then use the ToDictionary() method and lambdas to make a new Dictionary that translates the boolean field to an enum value. I need the values to be of the enum type, rather than the bool because there are many other statuses possible, but we only wanted to represent toggling between the two most common on the page.  \n\n```prettyprint lang-csharp\n\tvar dict = ((Dictionary<int, bool>)\n                JsonConvert.DeserializeObject\n                (lessonsStatuses, typeof(Dictionary<int, bool>))).ToDictionary\n                (x => x.Key, x => x.Value ? ObjectStatusEnum.Status1 : \t\t\t\t\t\tObjectStatusEnum.Status42);\n```","html":"<p>I'm getting some data in the form of a string as a key value pair collection of integer IDs and a boolean value(a status represented on the page by a checkbox). First, I call DeserializeObject() from the Json.NET library and convert the string to a Dictionary&lt;int, bool&gt;. I can then use the ToDictionary() method and lambdas to make a new Dictionary that translates the boolean field to an enum value. I need the values to be of the enum type, rather than the bool because there are many other statuses possible, but we only wanted to represent toggling between the two most common on the page.  </p>\n\n<pre><code class=\"language-prettyprint lang-csharp\">    var dict = ((Dictionary&lt;int, bool&gt;)\n                JsonConvert.DeserializeObject\n                (lessonsStatuses, typeof(Dictionary&lt;int, bool&gt;))).ToDictionary\n                (x =&gt; x.Key, x =&gt; x.Value ? ObjectStatusEnum.Status1 :                         ObjectStatusEnum.Status42);\n</code></pre>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2013-07-08T16:56:00.000Z","created_by":1,"updated_at":"2014-08-18T17:37:53.000Z","updated_by":1,"published_at":"2013-07-08T16:56:00.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":7,"uuid":"0c36eb20-0e8a-4654-bb43-a360cc694305","title":"Automatic Data Purging with MongoDB TTL","slug":"mongottl","markdown":"<img src=\"/content/images/2014/Jul/Title.jpg\" style=\"max-width: 100%\" />\nA common database maintenance scenario is the need to purge unneeded or expired data after a period of time, such as log messages or perhaps sensitive user data. With MongoDB, this can be easily accomplished with a built-in process. By creating a specialized index, we can make use of Mongo's [TTL feature][1]. This feature allows us to either purge documents at a specific date or specify an amount of time before the document expires.\n\n###Step 1: Design Decision\nWe have a relatively minor design choice to make regarding which field to create the index off of. Here are our options:\n\n - Specify a date the document should be deleted\n - Specify an amount of time the document has to live from the indexed field\n\nOftentimes, a collection will have been designed with some audit trail information in mind. There may be fields such as: createdBy, createDate, modifiedBy, modifiedDate. In this example, I already have a collection that contains these four audit fields. Therefore, I'm going to create my TTL index off of the createDate field and specify an expireAfterSeconds value. There are a few other rules to keep in mind when making this decision; the index must be [single field][2], [a date type][3], and the field may not already be part of another index. Lucky for me, my createDate meets the criteria. \n\n###Step 2: Creating the TTL Index\n\nI'm using [Mongoose][4] in my project, so in order to create the index, all I have to do is add 'expires' to 'createDate':\n\n```prettyprint lang-js\nvar mongoose = require('mongoose');\nvar Schema = mongoose.Schema;\n\nvar doomedDataSchema = new Schema({\n  name:  String,\n  title: String,\n  reasonForDoom: String,\n  notes: [{ note: String, noteDate: Date }],\n  audit: {\n    createdBy: String,\n    createDate:  { type: Date, expires: 60*60*24*30}, \n    modifiedBy: String,\n    modifiedDate: Date\n  }\n});\n```\n\nMy complicated math formula will set the document to be deleted after thirty days. According to the [API docs][5] on this subject, we don't need to specify an ugly number, but can substitute with an easier-to-read string value, like so:\n```prettyprint lang-js\n    createDate:  { type: Date, expires: '30d'}, \n```\nThat's it! Next time our code is started, the Mongoose schema will use the [ensureIndex][6] command behind the scenes to create the index if it doesn't already exist. The service that removes expired documents runs every 60 seconds.\n\n###Conclusion\nThe MongoDB TTL feature is a great tool to keep in mind when your project requires time-based data purging. This feature saves us the development time and overhead of writing our own, similar services and can be enabled from the Mongo shell, or in my case, using an ODM tool. \n\n\n  [1]: http://docs.mongodb.org/manual/tutorial/expire-data/\n  [2]: http://docs.mongodb.org/manual/core/index-single/\n  [3]: http://docs.mongodb.org/manual/reference/bson-types/#date\n  [4]: http://mongoosejs.com/\n  [5]: http://mongoosejs.com/docs/api.html#schema_date_SchemaDate-expires\n  [6]: http://docs.mongodb.org/manual/reference/method/db.collection.ensureIndex/","html":"<p><img src=\"/content/images/2014/Jul/Title.jpg\" style=\"max-width: 100%\" /> <br />\nA common database maintenance scenario is the need to purge unneeded or expired data after a period of time, such as log messages or perhaps sensitive user data. With MongoDB, this can be easily accomplished with a built-in process. By creating a specialized index, we can make use of Mongo's <a href=\"http://docs.mongodb.org/manual/tutorial/expire-data/\">TTL feature</a>. This feature allows us to either purge documents at a specific date or specify an amount of time before the document expires.</p>\n\n<h3 id=\"step1designdecision\">Step 1: Design Decision</h3>\n\n<p>We have a relatively minor design choice to make regarding which field to create the index off of. Here are our options:</p>\n\n<ul>\n<li>Specify a date the document should be deleted</li>\n<li>Specify an amount of time the document has to live from the indexed field</li>\n</ul>\n\n<p>Oftentimes, a collection will have been designed with some audit trail information in mind. There may be fields such as: createdBy, createDate, modifiedBy, modifiedDate. In this example, I already have a collection that contains these four audit fields. Therefore, I'm going to create my TTL index off of the createDate field and specify an expireAfterSeconds value. There are a few other rules to keep in mind when making this decision; the index must be <a href=\"http://docs.mongodb.org/manual/core/index-single/\">single field</a>, <a href=\"http://docs.mongodb.org/manual/reference/bson-types/#date\">a date type</a>, and the field may not already be part of another index. Lucky for me, my createDate meets the criteria. </p>\n\n<h3 id=\"step2creatingthettlindex\">Step 2: Creating the TTL Index</h3>\n\n<p>I'm using <a href=\"http://mongoosejs.com/\">Mongoose</a> in my project, so in order to create the index, all I have to do is add 'expires' to 'createDate':</p>\n\n<pre><code class=\"language-prettyprint lang-js\">var mongoose = require('mongoose');  \nvar Schema = mongoose.Schema;\n\nvar doomedDataSchema = new Schema({  \n  name:  String,\n  title: String,\n  reasonForDoom: String,\n  notes: [{ note: String, noteDate: Date }],\n  audit: {\n    createdBy: String,\n    createDate:  { type: Date, expires: 60*60*24*30}, \n    modifiedBy: String,\n    modifiedDate: Date\n  }\n});\n</code></pre>\n\n<p>My complicated math formula will set the document to be deleted after thirty days. According to the <a href=\"http://mongoosejs.com/docs/api.html#schema_date_SchemaDate-expires\">API docs</a> on this subject, we don't need to specify an ugly number, but can substitute with an easier-to-read string value, like so:  </p>\n\n<pre><code class=\"language-prettyprint lang-js\">    createDate:  { type: Date, expires: '30d'}, \n</code></pre>\n\n<p>That's it! Next time our code is started, the Mongoose schema will use the <a href=\"http://docs.mongodb.org/manual/reference/method/db.collection.ensureIndex/\">ensureIndex</a> command behind the scenes to create the index if it doesn't already exist. The service that removes expired documents runs every 60 seconds.</p>\n\n<h3 id=\"conclusion\">Conclusion</h3>\n\n<p>The MongoDB TTL feature is a great tool to keep in mind when your project requires time-based data purging. This feature saves us the development time and overhead of writing our own, similar services and can be enabled from the Mongo shell, or in my case, using an ODM tool. </p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2014-07-28T23:38:26.000Z","created_by":1,"updated_at":"2016-03-20T11:09:44.000Z","updated_by":1,"published_at":"2014-07-29T18:51:08.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":8,"uuid":"cc33ee1d-275d-4181-91e6-10fbdf1fb254","title":"Git for Hackathons","slug":"git-for-hackathons","markdown":"In a couple weeks, I will be participating in [The Nerdery's Overnight Website Challenge](http://chi2015.overnightwebsitechallenge.com/teams/191) and I have been designated as the team's DevOps. We've picked Git/GitHub for source control and I've been asked to give a quick demonstration on how we can be a more effective team by using it. Many sources online are targeted for individual developers working on personal projects or teams of developers collaborating on big projects (and rightly so). However, source control during a hackathon will need to be simple, straightforward, and just plain work. It should be a helpful tool for sharing code and files quickly instead of a time sink. There won't be time for build masters, branching strategies, peer reviews, or merge conflicts. So how will all this be managed and with a team who is largely unfamiliar or uninterested in Git/source control in general? I have no idea, but feel free to drop me a line if you do. The best way to teach something is to learn it, [right](http://en.wikipedia.org/wiki/Docendo_discimus)?\n\nHaving relatively little real-world experience with Git, I'm leaning heavily on the well-written Git and GitHub documentation for this article, plus numerous contributions by an awesome community while trying not to just create a huge link-storm.\n\n###About Git\nGit is a source control system originally authored by Linus Torvalds for work on the Linux kernel.[^n] Git is a [distributed version control system](http://git-scm.com/book/en/v2/Getting-Started-About-Version-Control#Distributed-Version-Control-Systems), which means every developer's machine has the database that contains the full history of the project's changes. Whether working alone or with a team, it's typically a good idea to have a server host the repository, which would be called a \"[remote](http://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes)\" in Git terms. On top of a bunch of other cool features, GitHub boils down to a remote server.\n\n###Installing Git\n[Just go here.](https://help.github.com/articles/set-up-git/) Most(all?) of my team members have Macs, except [me](http://en.wikipedia.org/wiki/Fight_the_Power); I'm certainly not qualified to explain how to install Git on a Mac. GitHub is though.\n\n###Administrators\nVersion control at your day job is going to be a different story than on a team during a hackathon. If your team is like mine, they mostly don't care about version control until it doesn't do what they want, then they get frustrated and curse the day computers were invented. If you can, try to do some prep work to make it as easy as possible for those sad individuals that don't study open source distributed version control systems in their spare time.\n\nIf you're planning on using GitHub during your event, a word of warning. I've been told that Internet connections at hackathons can be unpredictable and that a pragmatic approach would be to prepare for loss of connection. Considering having a spare machine or someone's laptop prepared to take over as a Git server, just in case.\n\n#####Remotes\nIf you do need to switch which server is hosting the master branch, [this page on remotes](http://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes) will be useful. It would be a good idea to instruct your teammates to add the possible remotes before the event. It's likely if you do this ahead of time on a physical machine, its IP address will change once you plug in to the event's network. Of course, if you bring your own, complete LAN, this won't be a problem, but if it becomes one, [this guide](https://help.github.com/articles/changing-a-remote-s-url/) will help update your team members.\n\n#####Bare\nWhen creating a repo that will be shared by team members, [that repo should be cloned or initialized as bare](http://www.gitguys.com/topics/shared-repositories-should-be-bare-repositories/). Bare means that no working directory will be created; if you will need to work on the same machine as the shared repo lives, do a normal clone from the bare repo. There is a [difference](http://stackoverflow.com/questions/2199897/how-to-convert-a-normal-git-repository-to-a-bare-one) between converting a normal repo to a bare one and cloning into a new bare repo, but for a hackathon, it probably won't be important.\n[Putting the bare repository on a server](http://git-scm.com/book/en/v2/Git-on-the-Server-Getting-Git-on-a-Server#Putting-the-Bare-Repository-on-a-Server)\n\n#####Users And Keys\nAsking fellow team members to create SSH keys for the possible remotes and/or GitHub ahead of time will be a time saver during the event; they won't need to worry about remembering or entering credentials on pushes. [The Git documentation](http://git-scm.com/book/en/v2/Git-on-the-Server-Getting-Git-on-a-Server#Small-Setups) explains that you can just create one \"git\" user on a server and have collaborators send you their public keys. With this method, the commit user data is retained and associated with the original committer, plus you won't need to create multiple temporary user accounts that will likely be unneeded after the event.\n[Generating SSH keys](https://help.github.com/articles/generating-ssh-keys/)<br/>\n[Generating your SSH public key](http://git-scm.com/book/en/v2/Git-on-the-Server-Generating-Your-SSH-Public-Key)\n\n\n###General Information On Workflows\n[This guide](http://rogerdudler.github.io/git-guide/) does a ridiculously good job of defining a simple, basic workflow with easy to understand commands.\n\n\n###Developers\nAs a developer, you'll want to get the latest version of the code before attempting to push your commits to the server. The recommended way of doing this would be with the [pull](http://git-scm.com/docs/git-pull) command because it executes both a [fetch](http://git-scm.com/docs/git-fetch) and [merge](http://git-scm.com/docs/git-merge) at the same time. This means you'll get the latest code committed by your colleagues and Git will attempt to auto-merge your changes in with any differences since you last fetched. If there is a conflict, Git will provide a list of the conflicted files. You will need to bring up each conflict in your text editor and resolve them before being allowed to push your commits to origin.\n[Resolving a merge conflict from the command line](https://help.github.com/articles/resolving-a-merge-conflict-from-the-command-line/)<br/>\n[Dealing with merge conflicts](http://www.git-tower.com/learn/ebook/command-line/advanced-topics/merge-conflicts)<br/>\n[Resolving conflicts](http://githowto.com/resolving_conflicts)<br/>\n[Stupid Git tricks](http://webchick.net/stupid-git-tricks)\n\n\nIf you're planning on using Sublime Text, you may want to give [this tutorial](https://scotch.io/tutorials/using-git-inside-of-sublime-text-to-improve-workflow) a read. It explains how to install and use the [Sublime Text Git](https://github.com/kemayo/sublime-text-git) package.\n\n###Designers\nAs a designer, you'll want a way to get your designs in front of the developers quickly and the developers will want a way to see your designs and changes in design(if any). GitHub has this problem solved in a spectacular way; If you view a commit that contains images you'll see [this](https://github.com/cameronmcefee/Image-Diff-View-Modes/commit/8e95f70c9c47168305970e91021072673d7cdad8). \n\n[Kaleidoscope](http://www.kaleidoscopeapp.com/) is a really cool looking diff tool that claims to be able to show diffs between image versions and boasts Git integration. \n\n###Other Links\n[Git cheat sheet](https://scotch.io/bar-talk/git-cheat-sheet)<br/>\n[Demo of the Bisect functionality](http://webchick.net/node/99) <br/>\n[Avoiding garbage commits when interrupted](http://24ways.org/2014/dealing-with-emergencies-in-git/)\n\n#####References\n[^n]: http://en.wikipedia.org/wiki/Git_%28software%29","html":"<p>In a couple weeks, I will be participating in <a href=\"http://chi2015.overnightwebsitechallenge.com/teams/191\">The Nerdery's Overnight Website Challenge</a> and I have been designated as the team's DevOps. We've picked Git/GitHub for source control and I've been asked to give a quick demonstration on how we can be a more effective team by using it. Many sources online are targeted for individual developers working on personal projects or teams of developers collaborating on big projects (and rightly so). However, source control during a hackathon will need to be simple, straightforward, and just plain work. It should be a helpful tool for sharing code and files quickly instead of a time sink. There won't be time for build masters, branching strategies, peer reviews, or merge conflicts. So how will all this be managed and with a team who is largely unfamiliar or uninterested in Git/source control in general? I have no idea, but feel free to drop me a line if you do. The best way to teach something is to learn it, <a href=\"http://en.wikipedia.org/wiki/Docendo_discimus\">right</a>?</p>\n\n<p>Having relatively little real-world experience with Git, I'm leaning heavily on the well-written Git and GitHub documentation for this article, plus numerous contributions by an awesome community while trying not to just create a huge link-storm.</p>\n\n<h3 id=\"aboutgit\">About Git</h3>\n\n<p>Git is a source control system originally authored by Linus Torvalds for work on the Linux kernel.<sup id=\"fnref:1\"><a href=\"#fn:1\" rel=\"footnote\">1</a></sup> Git is a <a href=\"http://git-scm.com/book/en/v2/Getting-Started-About-Version-Control#Distributed-Version-Control-Systems\">distributed version control system</a>, which means every developer's machine has the database that contains the full history of the project's changes. Whether working alone or with a team, it's typically a good idea to have a server host the repository, which would be called a \"<a href=\"http://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes\">remote</a>\" in Git terms. On top of a bunch of other cool features, GitHub boils down to a remote server.</p>\n\n<h3 id=\"installinggit\">Installing Git</h3>\n\n<p><a href=\"https://help.github.com/articles/set-up-git/\">Just go here.</a> Most(all?) of my team members have Macs, except <a href=\"http://en.wikipedia.org/wiki/Fight_the_Power\">me</a>; I'm certainly not qualified to explain how to install Git on a Mac. GitHub is though.</p>\n\n<h3 id=\"administrators\">Administrators</h3>\n\n<p>Version control at your day job is going to be a different story than on a team during a hackathon. If your team is like mine, they mostly don't care about version control until it doesn't do what they want, then they get frustrated and curse the day computers were invented. If you can, try to do some prep work to make it as easy as possible for those sad individuals that don't study open source distributed version control systems in their spare time.</p>\n\n<p>If you're planning on using GitHub during your event, a word of warning. I've been told that Internet connections at hackathons can be unpredictable and that a pragmatic approach would be to prepare for loss of connection. Considering having a spare machine or someone's laptop prepared to take over as a Git server, just in case.</p>\n\n<h5 id=\"remotes\">Remotes</h5>\n\n<p>If you do need to switch which server is hosting the master branch, <a href=\"http://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes\">this page on remotes</a> will be useful. It would be a good idea to instruct your teammates to add the possible remotes before the event. It's likely if you do this ahead of time on a physical machine, its IP address will change once you plug in to the event's network. Of course, if you bring your own, complete LAN, this won't be a problem, but if it becomes one, <a href=\"https://help.github.com/articles/changing-a-remote-s-url/\">this guide</a> will help update your team members.</p>\n\n<h5 id=\"bare\">Bare</h5>\n\n<p>When creating a repo that will be shared by team members, <a href=\"http://www.gitguys.com/topics/shared-repositories-should-be-bare-repositories/\">that repo should be cloned or initialized as bare</a>. Bare means that no working directory will be created; if you will need to work on the same machine as the shared repo lives, do a normal clone from the bare repo. There is a <a href=\"http://stackoverflow.com/questions/2199897/how-to-convert-a-normal-git-repository-to-a-bare-one\">difference</a> between converting a normal repo to a bare one and cloning into a new bare repo, but for a hackathon, it probably won't be important. <br />\n<a href=\"http://git-scm.com/book/en/v2/Git-on-the-Server-Getting-Git-on-a-Server#Putting-the-Bare-Repository-on-a-Server\">Putting the bare repository on a server</a></p>\n\n<h5 id=\"usersandkeys\">Users And Keys</h5>\n\n<p>Asking fellow team members to create SSH keys for the possible remotes and/or GitHub ahead of time will be a time saver during the event; they won't need to worry about remembering or entering credentials on pushes. <a href=\"http://git-scm.com/book/en/v2/Git-on-the-Server-Getting-Git-on-a-Server#Small-Setups\">The Git documentation</a> explains that you can just create one \"git\" user on a server and have collaborators send you their public keys. With this method, the commit user data is retained and associated with the original committer, plus you won't need to create multiple temporary user accounts that will likely be unneeded after the event. <br />\n<a href=\"https://help.github.com/articles/generating-ssh-keys/\">Generating SSH keys</a><br/>\n<a href=\"http://git-scm.com/book/en/v2/Git-on-the-Server-Generating-Your-SSH-Public-Key\">Generating your SSH public key</a></p>\n\n<h3 id=\"generalinformationonworkflows\">General Information On Workflows</h3>\n\n<p><a href=\"http://rogerdudler.github.io/git-guide/\">This guide</a> does a ridiculously good job of defining a simple, basic workflow with easy to understand commands.</p>\n\n<h3 id=\"developers\">Developers</h3>\n\n<p>As a developer, you'll want to get the latest version of the code before attempting to push your commits to the server. The recommended way of doing this would be with the <a href=\"http://git-scm.com/docs/git-pull\">pull</a> command because it executes both a <a href=\"http://git-scm.com/docs/git-fetch\">fetch</a> and <a href=\"http://git-scm.com/docs/git-merge\">merge</a> at the same time. This means you'll get the latest code committed by your colleagues and Git will attempt to auto-merge your changes in with any differences since you last fetched. If there is a conflict, Git will provide a list of the conflicted files. You will need to bring up each conflict in your text editor and resolve them before being allowed to push your commits to origin. <br />\n<a href=\"https://help.github.com/articles/resolving-a-merge-conflict-from-the-command-line/\">Resolving a merge conflict from the command line</a><br/>\n<a href=\"http://www.git-tower.com/learn/ebook/command-line/advanced-topics/merge-conflicts\">Dealing with merge conflicts</a><br/>\n<a href=\"http://githowto.com/resolving_conflicts\">Resolving conflicts</a><br/>\n<a href=\"http://webchick.net/stupid-git-tricks\">Stupid Git tricks</a></p>\n\n<p>If you're planning on using Sublime Text, you may want to give <a href=\"https://scotch.io/tutorials/using-git-inside-of-sublime-text-to-improve-workflow\">this tutorial</a> a read. It explains how to install and use the <a href=\"https://github.com/kemayo/sublime-text-git\">Sublime Text Git</a> package.</p>\n\n<h3 id=\"designers\">Designers</h3>\n\n<p>As a designer, you'll want a way to get your designs in front of the developers quickly and the developers will want a way to see your designs and changes in design(if any). GitHub has this problem solved in a spectacular way; If you view a commit that contains images you'll see <a href=\"https://github.com/cameronmcefee/Image-Diff-View-Modes/commit/8e95f70c9c47168305970e91021072673d7cdad8\">this</a>. </p>\n\n<p><a href=\"http://www.kaleidoscopeapp.com/\">Kaleidoscope</a> is a really cool looking diff tool that claims to be able to show diffs between image versions and boasts Git integration. </p>\n\n<h3 id=\"otherlinks\">Other Links</h3>\n\n<p><a href=\"https://scotch.io/bar-talk/git-cheat-sheet\">Git cheat sheet</a><br/>\n<a href=\"http://webchick.net/node/99\">Demo of the Bisect functionality</a> <br/>\n<a href=\"http://24ways.org/2014/dealing-with-emergencies-in-git/\">Avoiding garbage commits when interrupted</a></p>\n\n<h5 id=\"references\">References</h5>\n\n<div class=\"footnotes\"><ol><li class=\"footnote\" id=\"fn:1\"><p><a href=\"http://en.wikipedia.org/wiki/Git_%28software%29\">http://en.wikipedia.org/wiki/Git_%28software%29</a> <a href=\"#fnref:1\" title=\"return to article\">↩</a></p></li></ol></div>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2015-04-12T22:17:52.000Z","created_by":1,"updated_at":"2015-04-15T00:42:45.000Z","updated_by":1,"published_at":"2015-04-15T00:39:16.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":10,"uuid":"28fd9448-78d4-4f88-b747-03d9e991f49e","title":"Automating with the Amazon Web Services API: Keys","slug":"keys","markdown":"<img src=\"/content/images/2015/08/IAMKeys-1.jpg\" style=\"max-width: 100%\" />\nI got my first real exposure to cloud architecture a couple years ago. I was a contractor and the client wanted to track usage of Amazon Web Services(AWS) across different internal teams for financial reasons. They also realized the potential for automating infrastructure using the AWS API and wanted us to explore the numerous options while working with system administrators to define behavior. It was here that I got first-hand experience on how the cloud computing model enabled building and scaling systems where capacity is largely unknown. I was able to experiment with the ephemeral nature of the cloud and the many benefits it can bring to an organization. It's been awhile since that job, but it sparked a passion for cloud computing that I still carry. Like playing an old video game again, I want to re-explore some of the things I had done then and maybe pick up a few new tricks along the way. I'm also going to try to minimize my usage of the word \"cloud\" to avoid looking foolish with the numerous \"[cloud to X](https://chrome.google.com/webstore/detail/cloud-to-butt-plus/apmlngnhgbnjpajelfkmabhkfapgnoai?hl=en)\" plugins out there (or not, because it's hilarious every time).\n\n###Overview\nIn order to interact with the AWS API, you need a set of credentials to authenticate with. While you can create a root key with unlimited access to all account resources, it's generally recommended that you filter access with policies. In this article, I'll go through creating a user, placing that user in a group, and restricting AWS resource access by applying a policy to the group.\n\n###AWS Account and Free Tier\nAmazon offers a small taste of many of their services for free to whet your appetite. You can check out which services and the limitations at [https://aws.amazon.com/free/](https://aws.amazon.com/free/). Sign up if you haven't yet.\n\n###Create an IAM User and API Keys\nNow that you've got an account, we'll need to create a set of credentials to send along with each request to the AWS API before we can begin using it. When communicating with the AWS API, you need at a bare minimum the following pieces of data:\n\n<ul>\n<li>Access Key ID</li>\n<li>Secret Access Key</li>\n<li>Region</li>\n</ul>\n\nIf you're signed in to the [Amazon Console](https://console.aws.amazon.com/), click [IAM](https://console.aws.amazon.com/iam/home?), then \"Create New Users\". \n![](/content/images/2015/08/securityCreds-1.png)\n\nMake sure \"Generate an access key for each user\" is checked when creating users.\n<p>\n![](/content/images/2015/08/GenerateKeyForEachUser.jpg)\n<p>\nAfter creating the user(s), you will be shown an \"Access Key ID\" and a \"Secret Access Key\".\n\n###Is It Secret? Is It Safe?\nTreat these two strings as if they were passwords. With them, anyone can create, view, and modify anything within the applied policy. Don't check them into version control, don't email them to teammates or colleagues, don't post them to any \"Enter your AWS API key and we'll tell you how secure it is\" web forms. You only get this one chance to copy or download the secret key and please be careful with it.\n\n###Policing with Policies\nAn IAM policy is a JSON representation of what a user can and can not do within AWS. We can create a mix of whitelists and blacklists and also be very specific or very broad with resource permissions. Amazon recommends a practice called \"[least privilege](http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege)\", which means to only give permissions where needed. There are many example policies available in the AWS console, but we may as well make our own. Go to [Policies](https://console.aws.amazon.com/iam/home#policies) in IAM and click Get Started, then Create Policy, then Create Your Own Policy.\n![](/content/images/2015/08/CreatePolicy.jpg)\nHere we can write a JSON block explicitly calling out what this policy will allow/disallow. An in-depth explanation of the syntax can be found at the [Policy Grammar page](http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_grammar.html) of the IAM user guide. Something else of note is the way in which we reference AWS resources when granting permissions, [Amazon Resource Names(ARNs) and AWS Service Namespaces](http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html). We can specify entire AWS products to grant/deny the permission to all the way down to individual resources. To keep this simple, I'm going to create a policy that allows access to all EC2 resources. \n\n```prettyprint lang-json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"ec2:*\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        }\n    ]\n}\n```\n\n###Looking for Group\nNext we're going to create a group that we can apply a policy to. To avoid duplication of work later, it is considered good practice to add users to groups and apply policies to the groups instead of individual users. Go to the [Groups](https://console.aws.amazon.com/iam/home#groups) page under IAM and click \"Create New Group\". Give the group a name, click \"Next Step\" and here we can find the policy we just created, along with many pre-baked policies provided by Amazon. Click \"Next Step\" and create the group.\n![](/content/images/2015/08/CreateGroupAddPolicy.jpg)\n\n###Add User\nClick the group name, then \"Add Users to Group\", add the user(s) you created earlier. Now we can test the whole thing.\n\n###Policy Simulator\nAmazon provides an [IAM Policy Simulator](https://policysim.aws.amazon.com/home/index.jsp?#) to test actions against the API by certain users and groups. Select either the user or the group, select \"Amazon EC2\" and a few (or all) actions. Set Simulation Settings to which resources we want to test against and click \"Run Simulation\". You should see all \"allowed\" under the \"Permission\" column. The simulator is a powerful tool where you can experiment with policies and actions against AWS resources without actually performing them.\n\n![](/content/images/2015/08/PolicySimulator.jpg)\n\n###Conclusions\nYou can now use the access key ID and the secret access key in combination to start making AWS API EC2 calls. You'll need to make new policies to apply to groups or extend existing ones depending on your policy strategy as you automate AWS product usage. ","html":"<p><img src=\"/content/images/2015/08/IAMKeys-1.jpg\" style=\"max-width: 100%\" /> <br />\nI got my first real exposure to cloud architecture a couple years ago. I was a contractor and the client wanted to track usage of Amazon Web Services(AWS) across different internal teams for financial reasons. They also realized the potential for automating infrastructure using the AWS API and wanted us to explore the numerous options while working with system administrators to define behavior. It was here that I got first-hand experience on how the cloud computing model enabled building and scaling systems where capacity is largely unknown. I was able to experiment with the ephemeral nature of the cloud and the many benefits it can bring to an organization. It's been awhile since that job, but it sparked a passion for cloud computing that I still carry. Like playing an old video game again, I want to re-explore some of the things I had done then and maybe pick up a few new tricks along the way. I'm also going to try to minimize my usage of the word \"cloud\" to avoid looking foolish with the numerous \"<a href=\"https://chrome.google.com/webstore/detail/cloud-to-butt-plus/apmlngnhgbnjpajelfkmabhkfapgnoai?hl=en\">cloud to X</a>\" plugins out there (or not, because it's hilarious every time).</p>\n\n<h3 id=\"overview\">Overview</h3>\n\n<p>In order to interact with the AWS API, you need a set of credentials to authenticate with. While you can create a root key with unlimited access to all account resources, it's generally recommended that you filter access with policies. In this article, I'll go through creating a user, placing that user in a group, and restricting AWS resource access by applying a policy to the group.</p>\n\n<h3 id=\"awsaccountandfreetier\">AWS Account and Free Tier</h3>\n\n<p>Amazon offers a small taste of many of their services for free to whet your appetite. You can check out which services and the limitations at <a href=\"https://aws.amazon.com/free/\">https://aws.amazon.com/free/</a>. Sign up if you haven't yet.</p>\n\n<h3 id=\"createaniamuserandapikeys\">Create an IAM User and API Keys</h3>\n\n<p>Now that you've got an account, we'll need to create a set of credentials to send along with each request to the AWS API before we can begin using it. When communicating with the AWS API, you need at a bare minimum the following pieces of data:</p>\n\n<ul>  \n<li>Access Key ID</li>  \n<li>Secret Access Key</li>  \n<li>Region</li>  \n</ul>\n\n<p>If you're signed in to the <a href=\"https://console.aws.amazon.com/\">Amazon Console</a>, click <a href=\"https://console.aws.amazon.com/iam/home?\">IAM</a>, then \"Create New Users\". <br />\n<img src=\"/content/images/2015/08/securityCreds-1.png\" alt=\"\" /></p>\n\n<p>Make sure \"Generate an access key for each user\" is checked when creating users. <br />\n<p> <br />\n<img src=\"/content/images/2015/08/GenerateKeyForEachUser.jpg\" alt=\"\" />\n<p> <br />\nAfter creating the user(s), you will be shown an \"Access Key ID\" and a \"Secret Access Key\".</p>\n\n<h3 id=\"isitsecretisitsafe\">Is It Secret? Is It Safe?</h3>\n\n<p>Treat these two strings as if they were passwords. With them, anyone can create, view, and modify anything within the applied policy. Don't check them into version control, don't email them to teammates or colleagues, don't post them to any \"Enter your AWS API key and we'll tell you how secure it is\" web forms. You only get this one chance to copy or download the secret key and please be careful with it.</p>\n\n<h3 id=\"policingwithpolicies\">Policing with Policies</h3>\n\n<p>An IAM policy is a JSON representation of what a user can and can not do within AWS. We can create a mix of whitelists and blacklists and also be very specific or very broad with resource permissions. Amazon recommends a practice called \"<a href=\"http://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html#grant-least-privilege\">least privilege</a>\", which means to only give permissions where needed. There are many example policies available in the AWS console, but we may as well make our own. Go to <a href=\"https://console.aws.amazon.com/iam/home#policies\">Policies</a> in IAM and click Get Started, then Create Policy, then Create Your Own Policy. <br />\n<img src=\"/content/images/2015/08/CreatePolicy.jpg\" alt=\"\" />\nHere we can write a JSON block explicitly calling out what this policy will allow/disallow. An in-depth explanation of the syntax can be found at the <a href=\"http://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_grammar.html\">Policy Grammar page</a> of the IAM user guide. Something else of note is the way in which we reference AWS resources when granting permissions, <a href=\"http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names(ARNs) and AWS Service Namespaces</a>. We can specify entire AWS products to grant/deny the permission to all the way down to individual resources. To keep this simple, I'm going to create a policy that allows access to all EC2 resources. </p>\n\n<pre><code class=\"language-prettyprint lang-json\">{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"ec2:*\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        }\n    ]\n}\n</code></pre>\n\n<h3 id=\"lookingforgroup\">Looking for Group</h3>\n\n<p>Next we're going to create a group that we can apply a policy to. To avoid duplication of work later, it is considered good practice to add users to groups and apply policies to the groups instead of individual users. Go to the <a href=\"https://console.aws.amazon.com/iam/home#groups\">Groups</a> page under IAM and click \"Create New Group\". Give the group a name, click \"Next Step\" and here we can find the policy we just created, along with many pre-baked policies provided by Amazon. Click \"Next Step\" and create the group. <br />\n<img src=\"/content/images/2015/08/CreateGroupAddPolicy.jpg\" alt=\"\" /></p>\n\n<h3 id=\"adduser\">Add User</h3>\n\n<p>Click the group name, then \"Add Users to Group\", add the user(s) you created earlier. Now we can test the whole thing.</p>\n\n<h3 id=\"policysimulator\">Policy Simulator</h3>\n\n<p>Amazon provides an <a href=\"https://policysim.aws.amazon.com/home/index.jsp?#\">IAM Policy Simulator</a> to test actions against the API by certain users and groups. Select either the user or the group, select \"Amazon EC2\" and a few (or all) actions. Set Simulation Settings to which resources we want to test against and click \"Run Simulation\". You should see all \"allowed\" under the \"Permission\" column. The simulator is a powerful tool where you can experiment with policies and actions against AWS resources without actually performing them.</p>\n\n<p><img src=\"/content/images/2015/08/PolicySimulator.jpg\" alt=\"\" /></p>\n\n<h3 id=\"conclusions\">Conclusions</h3>\n\n<p>You can now use the access key ID and the secret access key in combination to start making AWS API EC2 calls. You'll need to make new policies to apply to groups or extend existing ones depending on your policy strategy as you automate AWS product usage. </p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2015-08-25T00:03:12.000Z","created_by":1,"updated_at":"2016-03-20T11:09:21.000Z","updated_by":1,"published_at":"2015-08-29T23:56:29.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":12,"uuid":"83505512-afec-4692-b131-04b99cc2d1c1","title":"Automating with the AWS API: Enabling Immutable Infrastructure","slug":"immutable","markdown":"<img src=\"/content/images/2015/10/Immutable.jpg\" style=\"max-width: 100%\" />\nOne of the biggest advantages to cloud computing is the ability to quickly react to an unknown system load. A well-known pattern within AWS is to make use of the [Auto Scaling](https://aws.amazon.com/autoscaling/) feature and adjust total computing capacity accordingly. That sounds great, but how do you go from this concept to an actual, working application? How do you deploy changes? Most important of all, how do you automate this process once you understand the architecture? Many of those questions can be answered with clever use of [Amazon Machine Images (AMIs)](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html). Here, I'll provide an example of a (rudimentary) system that exposes an endpoint to automate creation of a new, pre-configured AMI that will be ready for deployment into an Auto Scaled group.\n\n\n###Permissions Changes\nBefore starting, you'll want to make sure the [key](http://nicoll.io/keys) used to interface with AWS has the following permissions enabled:\n<li>[Run Instances](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html)\n<li>[Describe Instances](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html)\n<li>[Create Image](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateImage.html)\n<li>[Describe Images](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeImages.html)\n<li>[Terminate Instances](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_TerminateInstances.html)\n\n\nYour [policy](http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html) will look something like this:\n```prettyprint lang-json\n{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"ec2:RunInstances\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:DescribeInstances\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:CreateImage\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:DescribeImages\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:TerminateInstances\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        }\n    ]\n}\n```\n\n###Making Endpoints Meet\nI set out to make a simple system in which users would be able to automate deployments of their projects to an Auto Scaled group. The first step in this process would be to allow users to expose an endpoint that, when fired, will do the following:\n<li>Provision and configure a new EC2 instance\n<li>Freeze the instance's state in an AMI\n<li>Terminate the instance\n\nThis endpoint can be utilized as a [GitHub webhook](https://developer.github.com/webhooks/), [Git hook](http://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks), or even as part of a larger deployment pipeline after a number of build and test steps have successfully executed. I decided to call this system [Quadraxis](https://github.com/bgnicoll/quadraxis); I created a new [Laravel](http://laravel.com/) project, added the [AWS SDK for PHP](https://packagist.org/packages/aws/aws-sdk-php) to the composer.json file, then added the [keys](http://nicoll.io/keys) to the [.env](https://github.com/vlucas/phpdotenv) file. If you're interested, [Quadraxis](https://github.com/bgnicoll/quadraxis) is on GitHub, but the actual implementation of the system is less important than the concepts behind automating AMI creation. \n\n###Using User Data\nA crucial piece of this puzzle is solved with utilization of the [User Data](http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html) feature when creating an instance. User data can be passed to the API when launching an instance to provide an initialization script that will run once the instance is ready. I saved the exact script I used for this example in [this Gist](https://gist.github.com/bgnicoll/0c3cd95dd6d91d2bcbb7) for reference. Note that when trying to execute a bash script in User Data, it is important to include \"#!/bin/sh\" (or wherever shell might reside on your flavor of OS) as the first line. Also note this value needs to be base 64 encoded when submitting to the API. Of course, this step is made easier in this example by having the project in a public GitHub repository and written in an interpreted language. The endpoint created by Quadraxis will find the saved initialization script for the specific project and apply it when launching the instance.\n```prettyprint lang-php\n    public function webhook(Request $request, $name)\n    {\n        //Find the project\n        $project = Project::where('name', $name)\n                        ->get()\n                        ->first();\n        if (is_null($project)){\n            abort(404);\n        }\n        \n        //Instantiate the EC2 client\n        $ec2Client = Ec2Client::factory(array(\n            'region'  => getenv('AWS_REGION'),\n            'version' => '2012-10-17'\n        ));\n\n        //Launch the instance from a pre-determined AMI with saved\n        //user data and into a pre-configured security group\n        $result = $ec2Client->runInstances(array(\n            'ImageId'        => $project->base_ami_id,\n            'MinCount'       => 1,\n            'MaxCount'       => 1,\n            'InstanceType'   => 't2.medium',\n            'UserData'       => base64_encode(\n                                $project->init_script),\n            'SecurityGroups' => array('torvus-sec-group')\n        ));\n        \n        //Save the new instance ID for later\n        $instanceId = $result->search('Instances[0].InstanceId');\n    }\n```\n\n###Waiter, There's a Fly in My Soup\nBefore trying to create the image, the instance needs to be in a \"running\" state. We have a couple of options, such as polling [DescribeInstances](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html) until the instance is ready, or we could try using a \"waiter\". [Waiters](http://docs.aws.amazon.com/aws-sdk-php/v3/guide/guide/waiters.html) are a useful feature in many of the AWS SDKs that will allow you to wait for a resource to be in a specific state. We can extend the endpoint code further to wait until the instance is in a running state with a waiter.\n```prettyprint lang-php\n        $ec2Client->waitUntil('InstanceRunning', [\n            'InstanceIds' => array($instanceId)\n        ]);\n```\n\n###A Positive Self-Image\nOnce the instance is in a running state, we can issue the command to [create an image](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateImage.html). \n```prettyprint lang-php\n        $result = $ec2Client->createImage(array(\n            'InstanceId' => $instanceId,\n            'Name' => $project->name . time()\n        ));\n\n        $imageId = $result->search('ImageId');\n```\n\n###Custom \"Waiter\"\nNow we need to wait for the image creation to finish so we can terminate the instance, but there isn't a \"wait for this image to be available\" waiter out-of-the-box for the AWS SDK for PHP(at least I don't think there is). I simply wrote a loop that checks every thirty seconds for the image to be available. \n\n```prettyprint lang-php\n        while (1) { \n            $result = $ec2Client->describeImages(array(\n                'ImageIds' => array($imageId)\n            ));\n            $imageState = $result->search('Images[0].State');\n            if ($imageState == 'available') {\n                break;\n            }\n            sleep(30);\n        }\n```\n\n###Terminate the Instance\nWe have our deployable artifact, so we can terminate the instance used to create the AMI with the [TerminateInstances](http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_TerminateInstances.html) command:\n```prettyprint lang-php\n        $result = $ec2Client->terminateInstances(array(\n            'InstanceIds' => array($instanceId)\n        ));\n```\n\n###Wrapping Up\nWith this AMI, we now have what we need to start changes to an application down a deployment pipeline. You may be wondering about how to solve problems like environment configuration, managing DNS, or cycling out old instances in an automated fashion. I'm planning on continuing writing more functionality in Quadraxis to address these problems and using it as a backdrop for more posts like this one. Stay tuned! In the meantime, let me know what you think on Twitter, [@bgnicoll](https://twitter.com/bgnicoll).","html":"<p><img src=\"/content/images/2015/10/Immutable.jpg\" style=\"max-width: 100%\" /> <br />\nOne of the biggest advantages to cloud computing is the ability to quickly react to an unknown system load. A well-known pattern within AWS is to make use of the <a href=\"https://aws.amazon.com/autoscaling/\">Auto Scaling</a> feature and adjust total computing capacity accordingly. That sounds great, but how do you go from this concept to an actual, working application? How do you deploy changes? Most important of all, how do you automate this process once you understand the architecture? Many of those questions can be answered with clever use of <a href=\"http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AMIs.html\">Amazon Machine Images (AMIs)</a>. Here, I'll provide an example of a (rudimentary) system that exposes an endpoint to automate creation of a new, pre-configured AMI that will be ready for deployment into an Auto Scaled group.</p>\n\n<h3 id=\"permissionschanges\">Permissions Changes</h3>\n\n<p>Before starting, you'll want to make sure the <a href=\"http://nicoll.io/keys\">key</a> used to interface with AWS has the following permissions enabled: <br />\n<li><a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_RunInstances.html\">Run Instances</a> <br />\n<li><a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html\">Describe Instances</a> <br />\n<li><a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateImage.html\">Create Image</a> <br />\n<li><a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeImages.html\">Describe Images</a> <br />\n<li><a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_TerminateInstances.html\">Terminate Instances</a></p>\n\n<p>Your <a href=\"http://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html\">policy</a> will look something like this:  </p>\n\n<pre><code class=\"language-prettyprint lang-json\">{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Action\": \"ec2:RunInstances\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:DescribeInstances\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:CreateImage\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:DescribeImages\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        },\n        {\n            \"Action\": \"ec2:TerminateInstances\",\n            \"Effect\": \"Allow\",\n            \"Resource\": \"arn:aws:ec2\"\n        }\n    ]\n}\n</code></pre>\n\n<h3 id=\"makingendpointsmeet\">Making Endpoints Meet</h3>\n\n<p>I set out to make a simple system in which users would be able to automate deployments of their projects to an Auto Scaled group. The first step in this process would be to allow users to expose an endpoint that, when fired, will do the following: <br />\n<li>Provision and configure a new EC2 instance <br />\n<li>Freeze the instance's state in an AMI <br />\n<li>Terminate the instance</p>\n\n<p>This endpoint can be utilized as a <a href=\"https://developer.github.com/webhooks/\">GitHub webhook</a>, <a href=\"http://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks\">Git hook</a>, or even as part of a larger deployment pipeline after a number of build and test steps have successfully executed. I decided to call this system <a href=\"https://github.com/bgnicoll/quadraxis\">Quadraxis</a>; I created a new <a href=\"http://laravel.com/\">Laravel</a> project, added the <a href=\"https://packagist.org/packages/aws/aws-sdk-php\">AWS SDK for PHP</a> to the composer.json file, then added the <a href=\"http://nicoll.io/keys\">keys</a> to the <a href=\"https://github.com/vlucas/phpdotenv\">.env</a> file. If you're interested, <a href=\"https://github.com/bgnicoll/quadraxis\">Quadraxis</a> is on GitHub, but the actual implementation of the system is less important than the concepts behind automating AMI creation. </p>\n\n<h3 id=\"usinguserdata\">Using User Data</h3>\n\n<p>A crucial piece of this puzzle is solved with utilization of the <a href=\"http://docs.aws.amazon.com/AWSEC2/latest/UserGuide/user-data.html\">User Data</a> feature when creating an instance. User data can be passed to the API when launching an instance to provide an initialization script that will run once the instance is ready. I saved the exact script I used for this example in <a href=\"https://gist.github.com/bgnicoll/0c3cd95dd6d91d2bcbb7\">this Gist</a> for reference. Note that when trying to execute a bash script in User Data, it is important to include \"#!/bin/sh\" (or wherever shell might reside on your flavor of OS) as the first line. Also note this value needs to be base 64 encoded when submitting to the API. Of course, this step is made easier in this example by having the project in a public GitHub repository and written in an interpreted language. The endpoint created by Quadraxis will find the saved initialization script for the specific project and apply it when launching the instance.  </p>\n\n<pre><code class=\"language-prettyprint lang-php\">    public function webhook(Request $request, $name)\n    {\n        //Find the project\n        $project = Project::where('name', $name)\n                        -&gt;get()\n                        -&gt;first();\n        if (is_null($project)){\n            abort(404);\n        }\n\n        //Instantiate the EC2 client\n        $ec2Client = Ec2Client::factory(array(\n            'region'  =&gt; getenv('AWS_REGION'),\n            'version' =&gt; '2012-10-17'\n        ));\n\n        //Launch the instance from a pre-determined AMI with saved\n        //user data and into a pre-configured security group\n        $result = $ec2Client-&gt;runInstances(array(\n            'ImageId'        =&gt; $project-&gt;base_ami_id,\n            'MinCount'       =&gt; 1,\n            'MaxCount'       =&gt; 1,\n            'InstanceType'   =&gt; 't2.medium',\n            'UserData'       =&gt; base64_encode(\n                                $project-&gt;init_script),\n            'SecurityGroups' =&gt; array('torvus-sec-group')\n        ));\n\n        //Save the new instance ID for later\n        $instanceId = $result-&gt;search('Instances[0].InstanceId');\n    }\n</code></pre>\n\n<h3 id=\"waitertheresaflyinmysoup\">Waiter, There's a Fly in My Soup</h3>\n\n<p>Before trying to create the image, the instance needs to be in a \"running\" state. We have a couple of options, such as polling <a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_DescribeInstances.html\">DescribeInstances</a> until the instance is ready, or we could try using a \"waiter\". <a href=\"http://docs.aws.amazon.com/aws-sdk-php/v3/guide/guide/waiters.html\">Waiters</a> are a useful feature in many of the AWS SDKs that will allow you to wait for a resource to be in a specific state. We can extend the endpoint code further to wait until the instance is in a running state with a waiter.  </p>\n\n<pre><code class=\"language-prettyprint lang-php\">        $ec2Client-&gt;waitUntil('InstanceRunning', [\n            'InstanceIds' =&gt; array($instanceId)\n        ]);\n</code></pre>\n\n<h3 id=\"apositiveselfimage\">A Positive Self-Image</h3>\n\n<p>Once the instance is in a running state, we can issue the command to <a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_CreateImage.html\">create an image</a>.  </p>\n\n<pre><code class=\"language-prettyprint lang-php\">        $result = $ec2Client-&gt;createImage(array(\n            'InstanceId' =&gt; $instanceId,\n            'Name' =&gt; $project-&gt;name . time()\n        ));\n\n        $imageId = $result-&gt;search('ImageId');\n</code></pre>\n\n<h3 id=\"customwaiter\">Custom \"Waiter\"</h3>\n\n<p>Now we need to wait for the image creation to finish so we can terminate the instance, but there isn't a \"wait for this image to be available\" waiter out-of-the-box for the AWS SDK for PHP(at least I don't think there is). I simply wrote a loop that checks every thirty seconds for the image to be available. </p>\n\n<pre><code class=\"language-prettyprint lang-php\">        while (1) { \n            $result = $ec2Client-&gt;describeImages(array(\n                'ImageIds' =&gt; array($imageId)\n            ));\n            $imageState = $result-&gt;search('Images[0].State');\n            if ($imageState == 'available') {\n                break;\n            }\n            sleep(30);\n        }\n</code></pre>\n\n<h3 id=\"terminatetheinstance\">Terminate the Instance</h3>\n\n<p>We have our deployable artifact, so we can terminate the instance used to create the AMI with the <a href=\"http://docs.aws.amazon.com/AWSEC2/latest/APIReference/API_TerminateInstances.html\">TerminateInstances</a> command:  </p>\n\n<pre><code class=\"language-prettyprint lang-php\">        $result = $ec2Client-&gt;terminateInstances(array(\n            'InstanceIds' =&gt; array($instanceId)\n        ));\n</code></pre>\n\n<h3 id=\"wrappingup\">Wrapping Up</h3>\n\n<p>With this AMI, we now have what we need to start changes to an application down a deployment pipeline. You may be wondering about how to solve problems like environment configuration, managing DNS, or cycling out old instances in an automated fashion. I'm planning on continuing writing more functionality in Quadraxis to address these problems and using it as a backdrop for more posts like this one. Stay tuned! In the meantime, let me know what you think on Twitter, <a href=\"https://twitter.com/bgnicoll\">@bgnicoll</a>.</p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":"","meta_description":"","author_id":1,"created_at":"2015-09-20T10:28:17.000Z","created_by":1,"updated_at":"2016-03-20T11:08:42.000Z","updated_by":1,"published_at":"2015-10-18T13:34:18.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":14,"uuid":"142a6d6f-2187-45a3-b6b3-e67831ed9d79","title":"Querying Release Progression from the Octopus Deploy API","slug":"octo-progression","markdown":"<img src=\"/content/images/2016/02/OctopusProgressionHeader.png\" style=\"max-width: 100%\" />\nI built a tool this week that required retrieving release progression information from the Octopus Deploy API. While this information *is* exposed through the API, as of this writing, the [API documentation](https://github.com/OctopusDeploy/OctopusDeploy-Api/wiki/Progressions) is lacking for this functionality, and the [Octopus.Client](http://docs.octopusdeploy.com/display/OD/Octopus.Client) library doesn't provide an out-of-the-box way to query progressions.\n\n###\"Paste JSON as Classes\" (aka Cheating)\nIn order to get some objects to deserialize the Octopus JSON reponse into, first I queried my Octopus Server for a past release's progression. This can be found at **{Your Octopus Server}/api/releases/{release-id}/progression**. I copied the JSON output, created a new C# class, and made use of Visual Studio's \"Paste JSON as Classes\" feature.\n![](/content/images/2016/02/PasteJSONAsClasses.png)\nThis saved a lot of time as the JSON output from this API was fairly large and complicated. The pasted root object was aptly named \"Rootobject\" by Visual Studio. I changed that class name to **OctopusProgressionResponse** and left the other class names as generated.\n\n###Querying Progressions\nIn my situation, I know the Octopus Release ID ahead of time, so I'm able to query for progressions with code that looks something like this:\n\n```prettyprint lang-csharp\nvar octoServer = ConfigurationManager.AppSettings[\"OctopusServer\"];\nvar apiKey = ConfigurationManager.AppSettings[\"OctopusAPIKey\"];\nvar octoEndpoint = new OctopusServerEndpoint(octoServer, apiKey);\nvar octoRepo = new OctopusRepository(octoEndpoint);\nvar octoRelease = octoRepo.Releases.FindOne(x => x.Id == SOMEID);\nvar octoProgression = new OctopusProgressionResponse();\nif (octoRelease.HasLink(\"Progression\"))\n{\n    var progression = octoRelease.Links.Where(x => x.Key == \"Progression\").FirstOrDefault();\n    var httpClient = new HttpClient\n    {\n        Timeout = new TimeSpan(0, 0, 20),\n        BaseAddress = new Uri(ConfigurationManager.AppSettings[\"OctopusServer\"])\n    };\n    httpClient.DefaultRequestHeaders.Add(\"X-Octopus-ApiKey\", ConfigurationManager.AppSettings[\"OctopusAPIKey\"]);\n    var response = httpClient.GetAsync(progression.Value).Result;\n\n    if (response.IsSuccessStatusCode)\n    {\n        var responseContent = response.Content;\n        var responseString = responseContent.ReadAsStringAsync().Result;\n        octoProgression = JsonConvert.DeserializeObject<OctopusProgressionResponse>(responseString);\n    }\n}\n```\n\n###Conclusions\nIt's a bit of a let-down that this functionality is hidden so deeply, as it can be very useful while building tools that work in tandem with Octopus to keep track of where different versions of your software are at in the release process. The good news is that with a little bit of extra effort, we are able to extract this information from the Octopus API. Overall, I've been very impressed with the Octopus Deploy dev team's efforts to be \"[API-first](http://docs.octopusdeploy.com/display/OD/Octopus+REST+API)\"; using the Octopus.Client library is mostly a breeze. ","html":"<p><img src=\"/content/images/2016/02/OctopusProgressionHeader.png\" style=\"max-width: 100%\" /> <br />\nI built a tool this week that required retrieving release progression information from the Octopus Deploy API. While this information <em>is</em> exposed through the API, as of this writing, the <a href=\"https://github.com/OctopusDeploy/OctopusDeploy-Api/wiki/Progressions\">API documentation</a> is lacking for this functionality, and the <a href=\"http://docs.octopusdeploy.com/display/OD/Octopus.Client\">Octopus.Client</a> library doesn't provide an out-of-the-box way to query progressions.</p>\n\n<h3 id=\"pastejsonasclassesakacheating\">\"Paste JSON as Classes\" (aka Cheating)</h3>\n\n<p>In order to get some objects to deserialize the Octopus JSON reponse into, first I queried my Octopus Server for a past release's progression. This can be found at <strong>{Your Octopus Server}/api/releases/{release-id}/progression</strong>. I copied the JSON output, created a new C# class, and made use of Visual Studio's \"Paste JSON as Classes\" feature. <br />\n<img src=\"/content/images/2016/02/PasteJSONAsClasses.png\" alt=\"\" />\nThis saved a lot of time as the JSON output from this API was fairly large and complicated. The pasted root object was aptly named \"Rootobject\" by Visual Studio. I changed that class name to <strong>OctopusProgressionResponse</strong> and left the other class names as generated.</p>\n\n<h3 id=\"queryingprogressions\">Querying Progressions</h3>\n\n<p>In my situation, I know the Octopus Release ID ahead of time, so I'm able to query for progressions with code that looks something like this:</p>\n\n<pre><code class=\"language-prettyprint lang-csharp\">var octoServer = ConfigurationManager.AppSettings[\"OctopusServer\"];  \nvar apiKey = ConfigurationManager.AppSettings[\"OctopusAPIKey\"];  \nvar octoEndpoint = new OctopusServerEndpoint(octoServer, apiKey);  \nvar octoRepo = new OctopusRepository(octoEndpoint);  \nvar octoRelease = octoRepo.Releases.FindOne(x =&gt; x.Id == SOMEID);  \nvar octoProgression = new OctopusProgressionResponse();  \nif (octoRelease.HasLink(\"Progression\"))  \n{\n    var progression = octoRelease.Links.Where(x =&gt; x.Key == \"Progression\").FirstOrDefault();\n    var httpClient = new HttpClient\n    {\n        Timeout = new TimeSpan(0, 0, 20),\n        BaseAddress = new Uri(ConfigurationManager.AppSettings[\"OctopusServer\"])\n    };\n    httpClient.DefaultRequestHeaders.Add(\"X-Octopus-ApiKey\", ConfigurationManager.AppSettings[\"OctopusAPIKey\"]);\n    var response = httpClient.GetAsync(progression.Value).Result;\n\n    if (response.IsSuccessStatusCode)\n    {\n        var responseContent = response.Content;\n        var responseString = responseContent.ReadAsStringAsync().Result;\n        octoProgression = JsonConvert.DeserializeObject&lt;OctopusProgressionResponse&gt;(responseString);\n    }\n}\n</code></pre>\n\n<h3 id=\"conclusions\">Conclusions</h3>\n\n<p>It's a bit of a let-down that this functionality is hidden so deeply, as it can be very useful while building tools that work in tandem with Octopus to keep track of where different versions of your software are at in the release process. The good news is that with a little bit of extra effort, we are able to extract this information from the Octopus API. Overall, I've been very impressed with the Octopus Deploy dev team's efforts to be \"<a href=\"http://docs.octopusdeploy.com/display/OD/Octopus+REST+API\">API-first</a>\"; using the Octopus.Client library is mostly a breeze. </p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2016-02-04T23:53:02.000Z","created_by":1,"updated_at":"2016-03-20T11:07:59.000Z","updated_by":1,"published_at":"2016-02-05T01:21:34.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":15,"uuid":"31ee1389-590d-46f1-95d2-804f23b08259","title":"High Availability Web Server Caching with Redis","slug":"ha-cache","markdown":"<img src=\"/content/images/2016/03/CacheMoney.png\" style=\"max-width: 100%\" />\nOver the past few weeks, I've had the privilege of re-architecting the [fonts.com](http://www.fonts.com) web server caching strategy. The design isn't anything groundbreaking, but it was still fun to build and worth sharing. \n\n###Architecture Diagram\n![](/content/images/2016/03/CachingDiagram-1.png)\n<label style=\"text-align: center; display: block;\">**Figure 1.) My arrow game is on point**</label>\n\n###Breakdown\nThere are a few ideas at play here:\n<li style=\"font-size: 22px;\">The front-end web servers will attempt to serve data from their local read replica\n<li style=\"font-size: 22px;\">Sentinel instances will be running on each web server\n<li style=\"font-size: 22px;\">An additional failover replica is standing by in case the master goes down\n<li style=\"font-size: 22px;\">A stand-alone, tiebreaker Sentinel instance can achieve quorum with the web servers\n\n###Local Reads\nFonts.com typically requires two front-end web servers to meet demand(8 cores, 16 GB of RAM each). At our scale, it is within reason to have the master instance replicate to the two online web servers and the failover slave. The web servers are configured to attempt to read data from the local Redis instance before falling back to a more expensive source. The result is then serialized to JSON and [written](http://redis.io/commands/SET) as a normal string value to the current master instance. If the requested key is available locally, a network hop is saved. This strategy also eliminates the need for a potentially complicated cache invalidation mechanism; the same data will be replicated to each web server after any writes or deletes and keys with [TTLs](http://redis.io/commands/ttl) will expire at the same time.\n\n###Redis Sentinel\n[Redis Sentinel](http://redis.io/topics/sentinel) is a tool bundled with Redis that can help with monitoring and failover. It will periodically send pings to the current master to ensure it is still reachable. It also can automatically detect slaves and other Sentinels in the system (OK, so I left out some arrows from my diagram above). In the event a master becomes unreachable according to a Sentinel, it will communicate with other Sentinels to determine if a new master should be elected. If the (configurable) number of Sentinels agree that the master is down and a quorum is reached, a new master is elected and the web servers are informed they have a new destination for writes. By definition, quorum needs to be at least 51% consensus. In the event the master goes down, a quorum would be impossible with only the two web servers, so an additional Sentinel was configured on a stand-alone machine so quorum can be reached. \n\n###Slave Priority\nIt would be undesirable to allow the Sentinels to elect one of the read replicas running on the web servers as the new master during a failover. Luckily, the Redis instances themselves can be configured with a \"Slave Priority\". By setting a higher slave priority on the designated failover slave, the Sentinels will elect it as the new master during a failover. A value of \"0\" for slave-priority means that slave can never be elected master. \n<label style=\"text-align: center; display: block;\" >\n**[redis.conf](http://download.redis.io/redis-stable/redis.conf) settings:**  \n`slave-priority 0` for the web servers  \n`slave-priority 100` for the two potential masters  \n</label>\n###Disable Persistence\nFor a web server cache, on-disk persistence isn't really neccesary. Disable it by commenting out or removing the \"save\" lines and setting \"appendonly\" to \"no\" in redis.conf. (`save` examples are from the default redis.conf)\n<label style=\"text-align: center; display: block;\" >\n**[redis.conf](http://download.redis.io/redis-stable/redis.conf) settings:**  \n`# save 900 1`  \n`# save 300 10`  \n`# save 60 10000`  \n`appendonly no`\n</label>\n\n###Advantages\nThe most obvious advantage to this design is a local copy of shared data. Some of our cached objects can be somewhat large (Font data can be surprisingly complex. No, really). Retrieving from memory locally can be a nice time save.\n\nAnother advantage is that system-wide cache invalidation is trivial and the system is only a few milliseconds away from being in a consistent state after writes (barring network partitions of course, but that's what we get for favoring an [AP system](https://en.wikipedia.org/wiki/CAP_theorem)).\n###Drawbacks\nOne major drawback of this approach occurs during a failover. When Redis slaves change masters, every key is wiped from the database and the slave begins to sync with its new master from scratch. The new master will need to replicate to the read replicas on the web servers, which means it may be a potentially long time before we can start serving from cache again.\n\nAnother drawback is scalability. Adding more web servers to meet an increased demand means more replication from the master. Logic dictates there will also be more writes to the master with increased traffic to replicate. A different approach would likely be necessary under heavier load. \n\nFinally, the additional overhead of both a standalone Sentinel instance and an unused read replica can be considered a waste of resources for such a rare occurrence. \n\n###Conclusions\nLike everything in engineering, this design is a series of trade-offs. Overall, I'm happy with this approach and I'm confident it will produce great results in the near future. Time will tell if I'm right or not!","html":"<p><img src=\"/content/images/2016/03/CacheMoney.png\" style=\"max-width: 100%\" /> <br />\nOver the past few weeks, I've had the privilege of re-architecting the <a href=\"http://www.fonts.com\">fonts.com</a> web server caching strategy. The design isn't anything groundbreaking, but it was still fun to build and worth sharing. </p>\n\n<h3 id=\"architecturediagram\">Architecture Diagram</h3>\n\n<p><img src=\"/content/images/2016/03/CachingDiagram-1.png\" alt=\"\" />\n<label style=\"text-align: center; display: block;\"><strong>Figure 1.) My arrow game is on point</strong></label></p>\n\n<h3 id=\"breakdown\">Breakdown</h3>\n\n<p>There are a few ideas at play here: <br />\n<li style=\"font-size: 22px;\">The front-end web servers will attempt to serve data from their local read replica <br />\n<li style=\"font-size: 22px;\">Sentinel instances will be running on each web server <br />\n<li style=\"font-size: 22px;\">An additional failover replica is standing by in case the master goes down <br />\n<li style=\"font-size: 22px;\">A stand-alone, tiebreaker Sentinel instance can achieve quorum with the web servers</p>\n\n<h3 id=\"localreads\">Local Reads</h3>\n\n<p>Fonts.com typically requires two front-end web servers to meet demand(8 cores, 16 GB of RAM each). At our scale, it is within reason to have the master instance replicate to the two online web servers and the failover slave. The web servers are configured to attempt to read data from the local Redis instance before falling back to a more expensive source. The result is then serialized to JSON and <a href=\"http://redis.io/commands/SET\">written</a> as a normal string value to the current master instance. If the requested key is available locally, a network hop is saved. This strategy also eliminates the need for a potentially complicated cache invalidation mechanism; the same data will be replicated to each web server after any writes or deletes and keys with <a href=\"http://redis.io/commands/ttl\">TTLs</a> will expire at the same time.</p>\n\n<h3 id=\"redissentinel\">Redis Sentinel</h3>\n\n<p><a href=\"http://redis.io/topics/sentinel\">Redis Sentinel</a> is a tool bundled with Redis that can help with monitoring and failover. It will periodically send pings to the current master to ensure it is still reachable. It also can automatically detect slaves and other Sentinels in the system (OK, so I left out some arrows from my diagram above). In the event a master becomes unreachable according to a Sentinel, it will communicate with other Sentinels to determine if a new master should be elected. If the (configurable) number of Sentinels agree that the master is down and a quorum is reached, a new master is elected and the web servers are informed they have a new destination for writes. By definition, quorum needs to be at least 51% consensus. In the event the master goes down, a quorum would be impossible with only the two web servers, so an additional Sentinel was configured on a stand-alone machine so quorum can be reached. </p>\n\n<h3 id=\"slavepriority\">Slave Priority</h3>\n\n<p>It would be undesirable to allow the Sentinels to elect one of the read replicas running on the web servers as the new master during a failover. Luckily, the Redis instances themselves can be configured with a \"Slave Priority\". By setting a higher slave priority on the designated failover slave, the Sentinels will elect it as the new master during a failover. A value of \"0\" for slave-priority means that slave can never be elected master. <br />\n<label style=\"text-align: center; display: block;\" > <br />\n<strong><a href=\"http://download.redis.io/redis-stable/redis.conf\">redis.conf</a> settings:</strong> <br />\n<code>slave-priority 0</code> for the web servers <br />\n<code>slave-priority 100</code> for the two potential masters <br />\n</label>  </p>\n\n<h3 id=\"disablepersistence\">Disable Persistence</h3>\n\n<p>For a web server cache, on-disk persistence isn't really neccesary. Disable it by commenting out or removing the \"save\" lines and setting \"appendonly\" to \"no\" in redis.conf. (<code>save</code> examples are from the default redis.conf) <br />\n<label style=\"text-align: center; display: block;\" > <br />\n<strong><a href=\"http://download.redis.io/redis-stable/redis.conf\">redis.conf</a> settings:</strong> <br />\n<code># save 900 1</code> <br />\n<code># save 300 10</code> <br />\n<code># save 60 10000</code> <br />\n<code>appendonly no</code>\n</label></p>\n\n<h3 id=\"advantages\">Advantages</h3>\n\n<p>The most obvious advantage to this design is a local copy of shared data. Some of our cached objects can be somewhat large (Font data can be surprisingly complex. No, really). Retrieving from memory locally can be a nice time save.</p>\n\n<p>Another advantage is that system-wide cache invalidation is trivial and the system is only a few milliseconds away from being in a consistent state after writes (barring network partitions of course, but that's what we get for favoring an <a href=\"https://en.wikipedia.org/wiki/CAP_theorem\">AP system</a>).  </p>\n\n<h3 id=\"drawbacks\">Drawbacks</h3>\n\n<p>One major drawback of this approach occurs during a failover. When Redis slaves change masters, every key is wiped from the database and the slave begins to sync with its new master from scratch. The new master will need to replicate to the read replicas on the web servers, which means it may be a potentially long time before we can start serving from cache again.</p>\n\n<p>Another drawback is scalability. Adding more web servers to meet an increased demand means more replication from the master. Logic dictates there will also be more writes to the master with increased traffic to replicate. A different approach would likely be necessary under heavier load. </p>\n\n<p>Finally, the additional overhead of both a standalone Sentinel instance and an unused read replica can be considered a waste of resources for such a rare occurrence. </p>\n\n<h3 id=\"conclusions\">Conclusions</h3>\n\n<p>Like everything in engineering, this design is a series of trade-offs. Overall, I'm happy with this approach and I'm confident it will produce great results in the near future. Time will tell if I'm right or not!</p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2016-03-19T20:14:54.000Z","created_by":1,"updated_at":"2016-03-20T15:27:11.000Z","updated_by":1,"published_at":"2016-03-19T23:15:08.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":16,"uuid":"9d0aaece-e165-45a8-b637-3d71ceb316ec","title":"Building the Fonts.com Browse Filters Using Redis","slug":"fdc-browse","markdown":"<img src=\"/content/images/2017/02/BrowseHeader.png\" style=\"max-width: 100%\" />\nRecently on fonts.com, we released a new way to browse and discover fonts. We wanted this tool to be easy to use and return results quickly. In order to accomplish the latter, I made heavy use of Redis data structures and built-in commands. You can find the finished product at [fonts.com/browse](https://www.fonts.com/browse). The book *Redis in Action* by Dr. Josiah Carlson helped out immensely while building this feature. Specifically, Chapter 7 - *Search-Based Applications*. I would recommend picking up this book to anyone looking to use Redis in their application. \n\n##Building Inverted Indexes\nResults returned by the filters are on the font family level. For those unfamiliar, a family is a grouping of fonts of the same typeface. Fonts within a family vary by things like italic versions, bold versions, heavy weights, or light weights.\n\n![](https://cdnimg.fonts.net/CatalogImages/25/5390783.png)\n<label style=\"text-align: center; display: block;\">**Figure 1.) The 18 fonts making up the Neue Kabel family**</label>\n For the filters to work properly, the system needs to look at all fonts in a family and return that family as a result if one or more fonts has that corresponding characteristic. \n\nI chose to use the Redis SET data structure ([https://redis.io/topics/data-types#sets](https://redis.io/topics/data-types#sets)) to hold family IDs that all contain the same characteristic. This concept is called an [inverted index](https://en.wikipedia.org/wiki/Inverted_index). The time consuming thing here was coming up with SQL queries for each filter option.\n\n<img src=\"/content/images/2017/02/SetExample-2.png\" alt=\"\" style=\"display: block;margin: auto;\">\n\n<label style=\"text-align: center; display: block;\">**Table 1.) Example visualization of Redis SETs storing family IDs**</label>\n\n##Sort Ordering\n\nAs you may have noticed, Redis SETs are *unordered* lists of strings. The browse tool has four sorting options. \n\n<img src=\"/content/images/2017/02/SortOptions.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Figure 2.) Sorting options**</label>\n\n\nLuckily, we have another Redis data structure that can help. ZSETs ([https://redis.io/topics/data-types#sorted-sets](https://redis.io/topics/data-types#sorted-sets)) are sets that contain one additional piece of information, a numerical score. This data structure allowed me to pre-compute the complete order each family should appear in. \n\n<img src=\"/content/images/2017/02/SortZSETs-1.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Table 2.) Example visualization of Redis ZSETs storing sorted family IDs**</label>\n\n###Intersects and Unions\nWhen you click various filter options, the system combines the corresponding sets with each other and sorts them according to the selected sort option. The Redis command ZINTERSTORE ([https://redis.io/commands/zinterstore](https://redis.io/commands/zinterstore)) will combine n number of SETs together with logical AND operations, then sort them according to the ZSET scores, and finally create a new ZSET with the ordered results.\n\n<img src=\"/content/images/2017/02/ZInterstoreExample-2.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Figure 3.) ZINTERSTORE example**</label>\n\nFor the most part, this is straightforward, but one filter in particular causes some trouble.\n\n<img src=\"/content/images/2017/02/PriceSlider.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Figure 4.) Price slider**</label>\n\nThe other filter options such as languages, properties, and classifications are all inclusive (logical AND), but the pricing options are exclusive (logical OR). Redis doesn't have the capability to combine logical ANDs with logical ORs in the same command, so before applying the other filters I had to use SUNIONSTORE (https://redis.io/commands/sunionstore) with each selected price filter to create a single price SET with the desired options. \n\n##Paging\nThe result of the previous section is a ZSET containing the entire sorted list of the combined filter options. So how do we get a smaller subsection of this list to render a page? How do we know how to render the page count?\n\n<img src=\"/content/images/2017/02/PagingAndNumberOfResults-1.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Figure 5.) Number of results and pages**</label>\n\nWe can get the total number of items in a ZSET from the ZCARD command (https://redis.io/commands/zcard). We can get the desired page's family IDs by making use of the ZRANGE command (https://redis.io/commands/zrange)\n\n##Presentation Data\nAfter executing ZRANGE, we're left with an ordered subsection of family IDs. This is obviously not enough to render a page full of results. Part of the daily job that refreshes this data also retrieves and stores enough information for us to display each result. This meta data is stored in a Redis data structure called a HASH (https://redis.io/topics/data-types#hashes). HASHes are like mini-versions of Redis, containing n number of key-value pairs.\n\n<img src=\"/content/images/2017/02/HGETALL.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<img src=\"/content/images/2017/02/KabelPresentationData.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Figure 6.) Example of presentation data stored in Redis HASH**</label>\n\nDepending on your needs, you could also store this type of object in a plain string and serialized in JSON, [MessagePack](http://msgpack.org/), [Protocol Buffers](https://developers.google.com/protocol-buffers/), and so on. I chose a HASH in this instance so that individual fields could be accessed and updated without the need to read the entire object, make the modification, and write it back. Most of the presentation data changes very rarely, but we show an \"On Sale\" flag for families that are (you guessed it) on sale. Since promotions can come and go at any time, I have a job running every 10 minutes to make sure these values are up-to-date.\n\n##Dynamic Preview\nDynamic preview is what we call the preview style changing depending on which filter options you've selected. As I mentioned earlier, the results are displayed on a family level and reflect all fonts in a typeface, but we can only display a single style for the preview. Ordinarily when faced with this problem, we display the family preview in the \"normal\" weight, or *Roman* weight in typography terms. \n\nWith the release of this tool, certain filter options will change the preview style. Select \"Monospaced\", any \"Width\" option, or any \"Weight\" option and we try to show you the style you might be looking for as the preview style.\n\nI store a little bit of serialized data for each font in each family in Redis LISTs(https://redis.io/topics/data-types#lists). If you select any of the aforementioned filter options, I have logic in place to attempt to match your filter with an appropriate preview style. \n<img src=\"/content/images/2017/02/LRANGE-1.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<img src=\"/content/images/2017/02/DynamicPreview.png\" alt=\"\" style=\"display: block;margin: auto;\">\n<label style=\"text-align: center; display: block;\">**Figure 7.) Example of LRANGE usage and serialized dynamic preview meta data**</label>\n\n\n\n##Results\nAfter all this planning and research, it's nice to know that the hard work is paying off. Not only is the tool a success with users, but we're seeing very low latencies from the microservice I built to handle these requests. \n![](/content/images/2017/02/BrowseLatency.png)\n<label style=\"text-align: center; display: block;\">**Figure 8.) Seven day average latency data from New Relic**</label>\n\nThis feature has been my all-time favorite piece of software to write and it is certainly the thing I'm most proud of in my career. I couldn't have done it without the help of my teammates, [Piper Lawson](https://twitter.com/uxpiper) (UX\\UI) and [Reed Rizzo](https://twitter.com/reedling78) (Front End Developer). Without them, this feature would have looked something like this:\n```prettyprint lang-json\n{\n  \"TotalResults\": 20829,\n  \"Families\": [\n    {\n      \"FamilyId\": 1245395,\n      \"FamilyName\": \"Neue Helvetica®\",\n      \"FamilyURL\": \"font/linotype/neue-helvetica\",\n      \"OnSale\": false,\n      \"NumberOfStyles\": 59,\n      \"LicenseAvailability\": 95,\n      \"FoundryName\": \"Linotype\",\n      \"FoundryUrl\": \"font/linotype\",\n      \"FontFileMd5\": \"5a1d7e236d9bfb682fe593ff4b8608bd\",\n      \"InMLS\": true\n    }\n  ]\n}\n```\n<label style=\"text-align: center; display: block;\">**Figure 9.) Nobody wants to buy fonts this way**</label>\n\nWe hope you enjoy using this tool as much as we enjoyed building it!","html":"<p><img src=\"/content/images/2017/02/BrowseHeader.png\" style=\"max-width: 100%\" /> <br />\nRecently on fonts.com, we released a new way to browse and discover fonts. We wanted this tool to be easy to use and return results quickly. In order to accomplish the latter, I made heavy use of Redis data structures and built-in commands. You can find the finished product at <a href=\"https://www.fonts.com/browse\">fonts.com/browse</a>. The book <em>Redis in Action</em> by Dr. Josiah Carlson helped out immensely while building this feature. Specifically, Chapter 7 - <em>Search-Based Applications</em>. I would recommend picking up this book to anyone looking to use Redis in their application. </p>\n\n<h2 id=\"buildinginvertedindexes\">Building Inverted Indexes</h2>\n\n<p>Results returned by the filters are on the font family level. For those unfamiliar, a family is a grouping of fonts of the same typeface. Fonts within a family vary by things like italic versions, bold versions, heavy weights, or light weights.</p>\n\n<p><img src=\"https://cdnimg.fonts.net/CatalogImages/25/5390783.png\" alt=\"\" />\n<label style=\"text-align: center; display: block;\"><strong>Figure 1.) The 18 fonts making up the Neue Kabel family</strong></label> <br />\n For the filters to work properly, the system needs to look at all fonts in a family and return that family as a result if one or more fonts has that corresponding characteristic. </p>\n\n<p>I chose to use the Redis SET data structure (<a href=\"https://redis.io/topics/data-types#sets\">https://redis.io/topics/data-types#sets</a>) to hold family IDs that all contain the same characteristic. This concept is called an <a href=\"https://en.wikipedia.org/wiki/Inverted_index\">inverted index</a>. The time consuming thing here was coming up with SQL queries for each filter option.</p>\n\n<p><img src=\"/content/images/2017/02/SetExample-2.png\" alt=\"\" style=\"display: block;margin: auto;\"></p>\n\n<p><label style=\"text-align: center; display: block;\"><strong>Table 1.) Example visualization of Redis SETs storing family IDs</strong></label></p>\n\n<h2 id=\"sortordering\">Sort Ordering</h2>\n\n<p>As you may have noticed, Redis SETs are <em>unordered</em> lists of strings. The browse tool has four sorting options. </p>\n\n<p><img src=\"/content/images/2017/02/SortOptions.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Figure 2.) Sorting options</strong></label></p>\n\n<p>Luckily, we have another Redis data structure that can help. ZSETs (<a href=\"https://redis.io/topics/data-types#sorted-sets\">https://redis.io/topics/data-types#sorted-sets</a>) are sets that contain one additional piece of information, a numerical score. This data structure allowed me to pre-compute the complete order each family should appear in. </p>\n\n<p><img src=\"/content/images/2017/02/SortZSETs-1.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Table 2.) Example visualization of Redis ZSETs storing sorted family IDs</strong></label></p>\n\n<h3 id=\"intersectsandunions\">Intersects and Unions</h3>\n\n<p>When you click various filter options, the system combines the corresponding sets with each other and sorts them according to the selected sort option. The Redis command ZINTERSTORE (<a href=\"https://redis.io/commands/zinterstore\">https://redis.io/commands/zinterstore</a>) will combine n number of SETs together with logical AND operations, then sort them according to the ZSET scores, and finally create a new ZSET with the ordered results.</p>\n\n<p><img src=\"/content/images/2017/02/ZInterstoreExample-2.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Figure 3.) ZINTERSTORE example</strong></label></p>\n\n<p>For the most part, this is straightforward, but one filter in particular causes some trouble.</p>\n\n<p><img src=\"/content/images/2017/02/PriceSlider.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Figure 4.) Price slider</strong></label></p>\n\n<p>The other filter options such as languages, properties, and classifications are all inclusive (logical AND), but the pricing options are exclusive (logical OR). Redis doesn't have the capability to combine logical ANDs with logical ORs in the same command, so before applying the other filters I had to use SUNIONSTORE (<a href=\"https://redis.io/commands/sunionstore\">https://redis.io/commands/sunionstore</a>) with each selected price filter to create a single price SET with the desired options. </p>\n\n<h2 id=\"paging\">Paging</h2>\n\n<p>The result of the previous section is a ZSET containing the entire sorted list of the combined filter options. So how do we get a smaller subsection of this list to render a page? How do we know how to render the page count?</p>\n\n<p><img src=\"/content/images/2017/02/PagingAndNumberOfResults-1.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Figure 5.) Number of results and pages</strong></label></p>\n\n<p>We can get the total number of items in a ZSET from the ZCARD command (<a href=\"https://redis.io/commands/zcard\">https://redis.io/commands/zcard</a>). We can get the desired page's family IDs by making use of the ZRANGE command (<a href=\"https://redis.io/commands/zrange\">https://redis.io/commands/zrange</a>)</p>\n\n<h2 id=\"presentationdata\">Presentation Data</h2>\n\n<p>After executing ZRANGE, we're left with an ordered subsection of family IDs. This is obviously not enough to render a page full of results. Part of the daily job that refreshes this data also retrieves and stores enough information for us to display each result. This meta data is stored in a Redis data structure called a HASH (<a href=\"https://redis.io/topics/data-types#hashes\">https://redis.io/topics/data-types#hashes</a>). HASHes are like mini-versions of Redis, containing n number of key-value pairs.</p>\n\n<p><img src=\"/content/images/2017/02/HGETALL.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<img src=\"/content/images/2017/02/KabelPresentationData.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Figure 6.) Example of presentation data stored in Redis HASH</strong></label></p>\n\n<p>Depending on your needs, you could also store this type of object in a plain string and serialized in JSON, <a href=\"http://msgpack.org/\">MessagePack</a>, <a href=\"https://developers.google.com/protocol-buffers/\">Protocol Buffers</a>, and so on. I chose a HASH in this instance so that individual fields could be accessed and updated without the need to read the entire object, make the modification, and write it back. Most of the presentation data changes very rarely, but we show an \"On Sale\" flag for families that are (you guessed it) on sale. Since promotions can come and go at any time, I have a job running every 10 minutes to make sure these values are up-to-date.</p>\n\n<h2 id=\"dynamicpreview\">Dynamic Preview</h2>\n\n<p>Dynamic preview is what we call the preview style changing depending on which filter options you've selected. As I mentioned earlier, the results are displayed on a family level and reflect all fonts in a typeface, but we can only display a single style for the preview. Ordinarily when faced with this problem, we display the family preview in the \"normal\" weight, or <em>Roman</em> weight in typography terms. </p>\n\n<p>With the release of this tool, certain filter options will change the preview style. Select \"Monospaced\", any \"Width\" option, or any \"Weight\" option and we try to show you the style you might be looking for as the preview style.</p>\n\n<p>I store a little bit of serialized data for each font in each family in Redis LISTs(<a href=\"https://redis.io/topics/data-types#lists\">https://redis.io/topics/data-types#lists</a>). If you select any of the aforementioned filter options, I have logic in place to attempt to match your filter with an appropriate preview style. <br />\n<img src=\"/content/images/2017/02/LRANGE-1.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<img src=\"/content/images/2017/02/DynamicPreview.png\" alt=\"\" style=\"display: block;margin: auto;\"> <br />\n<label style=\"text-align: center; display: block;\"><strong>Figure 7.) Example of LRANGE usage and serialized dynamic preview meta data</strong></label></p>\n\n<h2 id=\"results\">Results</h2>\n\n<p>After all this planning and research, it's nice to know that the hard work is paying off. Not only is the tool a success with users, but we're seeing very low latencies from the microservice I built to handle these requests. <br />\n<img src=\"/content/images/2017/02/BrowseLatency.png\" alt=\"\" />\n<label style=\"text-align: center; display: block;\"><strong>Figure 8.) Seven day average latency data from New Relic</strong></label></p>\n\n<p>This feature has been my all-time favorite piece of software to write and it is certainly the thing I'm most proud of in my career. I couldn't have done it without the help of my teammates, <a href=\"https://twitter.com/uxpiper\">Piper Lawson</a> (UX\\UI) and <a href=\"https://twitter.com/reedling78\">Reed Rizzo</a> (Front End Developer). Without them, this feature would have looked something like this:  </p>\n\n<pre><code class=\"language-prettyprint lang-json\">{\n  \"TotalResults\": 20829,\n  \"Families\": [\n    {\n      \"FamilyId\": 1245395,\n      \"FamilyName\": \"Neue Helvetica®\",\n      \"FamilyURL\": \"font/linotype/neue-helvetica\",\n      \"OnSale\": false,\n      \"NumberOfStyles\": 59,\n      \"LicenseAvailability\": 95,\n      \"FoundryName\": \"Linotype\",\n      \"FoundryUrl\": \"font/linotype\",\n      \"FontFileMd5\": \"5a1d7e236d9bfb682fe593ff4b8608bd\",\n      \"InMLS\": true\n    }\n  ]\n}\n</code></pre>\n\n<p><label style=\"text-align: center; display: block;\"><strong>Figure 9.) Nobody wants to buy fonts this way</strong></label></p>\n\n<p>We hope you enjoy using this tool as much as we enjoyed building it!</p>","image":"/content/images/2017/02/BrowseHeaderTwitter-2.png","featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-02-25T19:54:02.000Z","created_by":1,"updated_at":"2017-05-04T17:16:54.000Z","updated_by":1,"published_at":"2017-02-26T06:07:25.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null},{"id":17,"uuid":"dd3e620a-32d1-4ecd-bf5d-358b5188cb18","title":"ButterCMS: A Headless CMS on Google Cloud Platform","slug":"butter-gcp","markdown":"In October of 2016, I authored the <a href=\"https://github.com/bgnicoll/buttercms-csharp\">C# library</a> for <a href=\"https://buttercms.com/\">ButterCMS</a>, a \"headless\" CMS with a SaaS offering. Recently, the folks at Butter reached out to me again to write an article to highlight the benefits of running a headless CMS on Google Cloud Platform. The resulting article was posted as a Google Cloud Platform Partner Solution and can be found at the following link: <a href=\"https://cloud.google.com/solutions/partners/butter-headless-cms-on-gcp\">https://cloud.google.com/solutions/partners/butter-headless-cms-on-gcp</a>. Thanks to the folks at Butter for giving me the opportunity!","html":"<p>In October of 2016, I authored the <a href=\"https://github.com/bgnicoll/buttercms-csharp\">C# library</a> for <a href=\"https://buttercms.com/\">ButterCMS</a>, a \"headless\" CMS with a SaaS offering. Recently, the folks at Butter reached out to me again to write an article to highlight the benefits of running a headless CMS on Google Cloud Platform. The resulting article was posted as a Google Cloud Platform Partner Solution and can be found at the following link: <a href=\"https://cloud.google.com/solutions/partners/butter-headless-cms-on-gcp\">https://cloud.google.com/solutions/partners/butter-headless-cms-on-gcp</a>. Thanks to the folks at Butter for giving me the opportunity!</p>","image":null,"featured":0,"page":0,"status":"published","language":"en_US","meta_title":null,"meta_description":null,"author_id":1,"created_at":"2017-09-21T17:40:49.000Z","created_by":1,"updated_at":"2017-09-21T18:05:04.000Z","updated_by":1,"published_at":"2017-09-21T18:05:04.000Z","published_by":1,"visibility":"public","mobiledoc":null,"amp":null}],"posts_tags":[{"id":1,"post_id":12,"tag_id":2,"sort_order":0},{"id":2,"post_id":12,"tag_id":3,"sort_order":1},{"id":3,"post_id":10,"tag_id":2,"sort_order":0},{"id":4,"post_id":10,"tag_id":3,"sort_order":1},{"id":5,"post_id":14,"tag_id":4,"sort_order":0},{"id":6,"post_id":15,"tag_id":5,"sort_order":0},{"id":7,"post_id":16,"tag_id":5,"sort_order":0},{"id":8,"post_id":17,"tag_id":6,"sort_order":0},{"id":9,"post_id":17,"tag_id":7,"sort_order":1}],"roles":[{"id":1,"uuid":"a253af2a-0e5e-40fb-a948-456b55f9ee24","name":"Administrator","description":"Administrators","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2014-07-23T14:33:54.000Z","updated_by":1},{"id":2,"uuid":"2cbfeef0-6a14-4196-b37a-3e4e1c65cd6e","name":"Editor","description":"Editors","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2014-07-23T14:33:54.000Z","updated_by":1},{"id":3,"uuid":"6606545c-59c9-4610-87dd-f6f2dc5e064d","name":"Author","description":"Authors","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2014-07-23T14:33:54.000Z","updated_by":1},{"id":4,"uuid":"8554ece1-d2c7-4349-863d-61a7b2849742","name":"Owner","description":"Blog Owner","created_at":"2014-08-11T17:06:41.000Z","created_by":1,"updated_at":"2014-08-11T17:06:41.000Z","updated_by":1}],"roles_users":[{"id":1,"role_id":4,"user_id":1}],"settings":[{"id":1,"uuid":"e64bcef2-a2af-4e0f-8e40-59840ac60a65","key":"databaseVersion","value":"009","type":"core","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":2,"uuid":"1b6415e6-21b4-4a31-8739-4534bd120c26","key":"dbHash","value":"aeb6fe23-ad3b-4b1f-a2e0-96ceab99143a","type":"core","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":3,"uuid":"0a2a342f-2a58-4f3f-a0ac-e44286172189","key":"nextUpdateCheck","value":"1508436090","type":"core","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2017-10-18T18:01:29.000Z","updated_by":1},{"id":4,"uuid":"4bfe70af-e829-4997-98c5-106299df492c","key":"displayUpdateNotification","value":null,"type":"core","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":5,"uuid":"c773bf2f-f672-4846-a3a0-e5d30f9ddf25","key":"title","value":"Brandon Nicoll","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":6,"uuid":"31386c82-b8d4-48a5-8f14-3f775e295500","key":"description","value":"","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":7,"uuid":"8e607216-7929-41a0-b859-440233f93068","key":"email","value":"bgnicoll@gmail.com","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":8,"uuid":"e2e655ed-253c-496d-a4c5-029af6898bcf","key":"logo","value":"/content/images/2015/09/IMG_20150919_170828.jpg","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":9,"uuid":"6b28b131-829b-490e-ac78-defb15033665","key":"cover","value":"/content/images/2016/03/FiddleCopy.jpg","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":10,"uuid":"514d4c41-9833-455c-91f8-ab07549ef610","key":"defaultLang","value":"en_US","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":11,"uuid":"8ef3b182-565d-438c-b3dc-aa87b7a3cc2e","key":"postsPerPage","value":"6","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":12,"uuid":"66bc7fb3-5f70-47d8-9fb7-3cfc751c66d8","key":"forceI18n","value":"true","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":13,"uuid":"661ee053-9415-4131-99fd-d9e2248eb63a","key":"permalinks","value":"/:slug/","type":"blog","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":14,"uuid":"dfb5cfb4-076d-4eb1-8232-1143491ac643","key":"activeTheme","value":"custom_theme","type":"theme","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":15,"uuid":"7610c965-2a56-4ac6-8c05-5a84705f5547","key":"activeApps","value":"[]","type":"app","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":16,"uuid":"b8a372fa-9e93-4851-9f50-ca70a71e48b6","key":"installedApps","value":"[]","type":"app","created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2017-10-18T17:56:47.000Z","updated_by":1},{"id":17,"uuid":"1aab83a4-8f42-4d2e-a07f-97d2dfaf51f3","key":"ghost_head","value":"<meta name=\"google-site-verification\" content=\"Y2ew6OOC-e7vo4PvXSqV9EhM4wx9jlh8D-PZWJTs_Og\" />","type":"blog","created_at":"2014-12-05T17:54:22.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":18,"uuid":"9a0134a7-6684-4cb4-b03b-bda754ba4672","key":"ghost_foot","value":"<!-- You can safely delete this line if your theme does not require jQuery -->\n<script type=\"text/javascript\" src=\"https://code.jquery.com/jquery-1.11.3.min.js\"></script>\n\n","type":"blog","created_at":"2014-12-05T17:54:22.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":19,"uuid":"69d882c7-9a13-4da0-bea4-8d7497aceed7","key":"labs","value":"{}","type":"blog","created_at":"2015-01-13T02:29:08.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":20,"uuid":"1443dbbf-63ad-4707-8c17-2c4f20e62dc0","key":"navigation","value":"[{\"label\":\"Home\", \"url\":\"/\"}]","type":"blog","created_at":"2015-02-28T23:09:02.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":21,"uuid":"28528015-a850-459b-9a67-abc9841587a1","key":"isPrivate","value":"false","type":"private","created_at":"2015-05-14T17:27:22.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":22,"uuid":"57a9b851-d2b0-4f15-b3bd-f6f503ac65a0","key":"password","value":"","type":"private","created_at":"2015-05-14T17:27:22.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":23,"uuid":"18dd4a27-c303-464a-ad28-decc339920e7","key":"twitter","value":"","type":"blog","created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":24,"uuid":"ae21e921-6a25-4cb4-82c7-b4cbef482707","key":"slack","value":"[{\"url\":\"\"}]","type":"blog","created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":25,"uuid":"222a25ac-8ec7-4f05-9a7c-936219e2731f","key":"facebook","value":"","type":"blog","created_at":"2016-05-18T12:58:56.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":26,"uuid":"9bd13888-a181-494b-8312-dbfbc1fdc4df","key":"seenNotifications","value":"[]","type":"core","created_at":"2016-07-27T07:49:31.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":27,"uuid":"9f4679a1-2a68-4c2d-b2b9-fe0f1ff871b2","key":"migrations","value":"{\"006/01\":\"2016-07-27T08:49:33Z\"}","type":"core","created_at":"2016-07-27T08:49:31.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":28,"uuid":"8186bc2e-3145-400e-9abd-a39b2717f07f","key":"activeTimezone","value":"Etc/UTC","type":"blog","created_at":"2016-07-27T07:49:31.000Z","created_by":1,"updated_at":"2016-07-27T08:49:33.000Z","updated_by":1},{"id":29,"uuid":"3e331bba-a17f-404c-93c8-caf3b11a5d8b","key":"amp","value":"true","type":"blog","created_at":"2017-01-12T18:56:33.000Z","created_by":1,"updated_at":"2017-01-12T18:56:33.000Z","updated_by":1},{"id":30,"uuid":"365ee2c8-839f-47ab-a4da-dc93fdc1e1c0","key":"notifications","value":"[]","type":"core","created_at":"2017-10-16T11:54:13.000Z","created_by":1,"updated_at":"2017-10-16T11:54:13.000Z","updated_by":1}],"subscribers":[],"tags":[{"id":1,"uuid":"bcb974db-fe79-4e8f-8c5d-2c8d2625a6fe","name":"Getting Started","slug":"getting-started","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2014-07-23T14:33:54.000Z","created_by":1,"updated_at":"2014-07-23T14:33:54.000Z","updated_by":1,"image":null,"visibility":"public"},{"id":2,"uuid":"a18f1ed6-e87c-4de2-adcc-8d4105b9cdde","name":"AWS","slug":"aws","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-10-07T22:47:22.000Z","created_by":1,"updated_at":"2015-10-07T22:47:22.000Z","updated_by":1,"image":null,"visibility":"public"},{"id":3,"uuid":"059e4475-866c-4def-a5b3-6d323ffa87f8","name":"Automation","slug":"automation","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2015-10-07T22:47:22.000Z","created_by":1,"updated_at":"2015-10-07T22:47:22.000Z","updated_by":1,"image":null,"visibility":"public"},{"id":4,"uuid":"983824aa-4a09-478a-9bc5-fd835864f1a6","name":"OctopusDeploy","slug":"octopusdeploy","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2016-02-05T01:22:48.000Z","created_by":1,"updated_at":"2016-02-05T01:22:48.000Z","updated_by":1,"image":null,"visibility":"public"},{"id":5,"uuid":"828563f5-13d5-4f88-acd2-483030c9f082","name":"Redis","slug":"redis","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2016-03-19T20:18:19.000Z","created_by":1,"updated_at":"2016-03-19T20:18:19.000Z","updated_by":1,"image":null,"visibility":"public"},{"id":6,"uuid":"40f52a36-d906-4768-b627-005279ba91f9","name":"Google Cloud Platform","slug":"google-cloud-platform","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2017-09-21T17:40:49.000Z","created_by":1,"updated_at":"2017-09-21T17:43:06.000Z","updated_by":1,"image":null,"visibility":"public"},{"id":7,"uuid":"213caebe-72ed-4c5b-bd58-880d53851a62","name":"buttercms","slug":"buttercms","description":null,"parent_id":null,"meta_title":null,"meta_description":null,"created_at":"2017-09-21T18:05:00.000Z","created_by":1,"updated_at":"2017-09-21T18:05:00.000Z","updated_by":1,"image":null,"visibility":"public"}],"users":[{"id":1,"uuid":"73e8b51b-489f-4d50-8368-83ba3e0be625","name":"Brandon Nicoll","slug":"brandon-nicoll","password":"$2a$10$ZFKvc3StNbOHK9LpmGonfuZbL6kxWi3VGXxeKkty8kOPxyGOGWwtO","email":"bgnicoll@gmail.com","image":null,"cover":null,"bio":"","website":"","location":"Chicago","accessibility":null,"status":"active","language":"en_US","meta_title":null,"meta_description":null,"last_login":"2017-10-18T18:04:50.000Z","created_at":"2014-07-23T16:05:05.000Z","created_by":1,"updated_at":"2017-10-18T18:04:50.000Z","updated_by":1,"tour":null,"visibility":"public","facebook":null,"twitter":null}]}}]}